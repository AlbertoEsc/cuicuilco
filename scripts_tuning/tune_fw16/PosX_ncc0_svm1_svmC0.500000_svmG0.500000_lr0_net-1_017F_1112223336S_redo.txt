Adding train_params to mdp.Node:  AdaptiveCutoffNode
Adding train_params to mdp.Node:  Convolution2DNode
Adding train_params to mdp.Node:  CuBICANode
Adding train_params to mdp.Node:  CutoffNode
Adding train_params to mdp.Node:  DiscreteHopfieldClassifier
Adding train_params to mdp.Node:  EtaComputerNode
Adding train_params to mdp.Node:  FANode
Adding train_params to mdp.Node:  FDANode
Adding train_params to mdp.Node:  FastICANode
Adding train_params to mdp.Node:  GaussianClassifier
Adding train_params to mdp.Node:  GeneralExpansionNode
Adding train_params to mdp.Node:  GrowingNeuralGasExpansionNode
Adding train_params to mdp.Node:  GrowingNeuralGasNode
Adding train_params to mdp.Node:  HLLENode
Adding train_params to mdp.Node:  HeadNode
Adding train_params to mdp.Node:  HistogramNode
Adding train_params to mdp.Node:  HitParadeNode
Adding train_params to mdp.Node:  ICANode
Adding train_params to mdp.Node:  IEVMLRecNode
Adding train_params to mdp.Node:  IEVMNode
Adding train_params to mdp.Node:  ISFANode
Adding train_params to mdp.Node:  IdentityNode
Adding train_params to mdp.Node:  JADENode
Adding train_params to mdp.Node:  KMeansClassifier
Adding train_params to mdp.Node:  KNNClassifier
Adding train_params to mdp.Node:  LLENode
Adding train_params to mdp.Node:  LibSVMClassifier
Adding train_params to mdp.Node:  LinearRegressionNode
Adding train_params to mdp.Node:  NIPALSNode
Adding train_params to mdp.Node:  NearestMeanClassifier
Adding train_params to mdp.Node:  NoiseNode
Adding train_params to mdp.Node:  NormalNoiseNode
Adding train_params to mdp.Node:  NormalizeNode
Adding train_params to mdp.Node:  PCANode
Adding train_params to mdp.Node:  PInvSwitchboard
Adding train_params to mdp.Node:  PerceptronClassifier
Adding train_params to mdp.Node:  PointwiseFunctionNode
Adding train_params to mdp.Node:  PolynomialExpansionNode
Adding train_params to mdp.Node:  QuadraticExpansionNode
Adding train_params to mdp.Node:  RBFExpansionNode
Adding train_params to mdp.Node:  RBMNode
Adding train_params to mdp.Node:  RBMWithLabelsNode
Adding train_params to mdp.Node:  RandomPermutationNode
Adding train_params to mdp.Node:  RandomizedMaskNode
Adding train_params to mdp.Node:  SFA2Node
Adding train_params to mdp.Node:  SFANode
Adding train_params to mdp.Node:  SFAPCANode
Adding train_params to mdp.Node:  SignumClassifier
Adding train_params to mdp.Node:  SimpleMarkovClassifier
Adding train_params to mdp.Node:  TDSEPNode
Adding train_params to mdp.Node:  TimeDelayNode
Adding train_params to mdp.Node:  TimeDelaySlidingWindowNode
Adding train_params to mdp.Node:  TimeFramesNode
Adding train_params to mdp.Node:  WhiteningNode
Adding train_params to mdp.Node:  XSFANode
Adding train_params to (hinet) mdp.Node:  ChannelSwitchboard
Adding train_params to (hinet) mdp.Node:  DoubleRect2dSwitchboard
Adding train_params to (hinet) mdp.Node:  DoubleRhomb2dSwitchboard
Adding train_params to (hinet) mdp.Node:  FactoryDoubleRect2dSwitchboard
Adding train_params to (hinet) mdp.Node:  FactoryDoubleRhomb2dSwitchboard
Adding train_params to (hinet) mdp.Node:  FactoryExtensionChannelSwitchboard
Adding train_params to (hinet) mdp.Node:  FactoryRectangular2dSwitchboard
Adding train_params to (hinet) mdp.Node:  FlowNode
Adding train_params to (hinet) mdp.Node:  MeanInverseSwitchboard
Adding train_params to (hinet) mdp.Node:  Rectangular2dSwitchboard
Adding train_params to (hinet) mdp.Node:  Switchboard
<class 'mdp.nodes.AdaptiveCutoffNode'>
Adding execute_data_vec to node: AdaptiveCutoffNode
<class 'mdp.nodes.Convolution2DNode'>
Adding execute_data_vec to node: Convolution2DNode
<class 'mdp.nodes.CuBICANode'>
Adding execute_data_vec to node: CuBICANode
<class 'mdp.nodes.CutoffNode'>
Adding execute_data_vec to node: CutoffNode
<class 'mdp.nodes.DiscreteHopfieldClassifier'>
Adding execute_data_vec to node: DiscreteHopfieldClassifier
<class 'mdp.nodes.EtaComputerNode'>
Adding execute_data_vec to node: EtaComputerNode
<class 'mdp.nodes.FANode'>
Adding execute_data_vec to node: FANode
<class 'mdp.nodes.FDANode'>
Adding execute_data_vec to node: FDANode
<class 'mdp.nodes.FastICANode'>
Adding execute_data_vec to node: FastICANode
<class 'mdp.nodes.GaussianClassifier'>
Adding execute_data_vec to node: GaussianClassifier
<class 'more_nodes.GeneralExpansionNode'>
Adding execute_data_vec to node: GeneralExpansionNode
<class 'mdp.nodes.GrowingNeuralGasExpansionNode'>
Adding execute_data_vec to node: GrowingNeuralGasExpansionNode
<class 'mdp.nodes.GrowingNeuralGasNode'>
Adding execute_data_vec to node: GrowingNeuralGasNode
<class 'mdp.nodes.HLLENode'>
Adding execute_data_vec to node: HLLENode
<class 'more_nodes.HeadNode'>
Adding execute_data_vec to node: HeadNode
<class 'mdp.nodes.HistogramNode'>
Adding execute_data_vec to node: HistogramNode
<class 'mdp.nodes.HitParadeNode'>
Adding execute_data_vec to node: HitParadeNode
<class 'mdp.nodes.ica_nodes.ICANode'>
Adding execute_data_vec to node: ICANode
<class 'more_nodes.IEVMLRecNode'>
Adding execute_data_vec to node: IEVMLRecNode
<class 'more_nodes.IEVMNode'>
Adding execute_data_vec to node: IEVMNode
<class 'mdp.nodes.ISFANode'>
Adding execute_data_vec to node: ISFANode
<class 'mdp.nodes.IdentityNode'>
Adding execute_data_vec to node: IdentityNode
<class 'mdp.nodes.JADENode'>
Adding execute_data_vec to node: JADENode
<class 'mdp.nodes.KMeansClassifier'>
Adding execute_data_vec to node: KMeansClassifier
<class 'mdp.nodes.KNNClassifier'>
Adding execute_data_vec to node: KNNClassifier
<class 'mdp.nodes.LLENode'>
Adding execute_data_vec to node: LLENode
<class 'mdp.nodes.LibSVMClassifier'>
Adding execute_data_vec to node: LibSVMClassifier
<class 'mdp.nodes.LinearRegressionNode'>
Adding execute_data_vec to node: LinearRegressionNode
<class 'mdp.nodes.NIPALSNode'>
Adding execute_data_vec to node: NIPALSNode
<class 'mdp.nodes.NearestMeanClassifier'>
Adding execute_data_vec to node: NearestMeanClassifier
<class 'mdp.nodes.NoiseNode'>
Adding execute_data_vec to node: NoiseNode
<class 'mdp.nodes.NormalNoiseNode'>
Adding execute_data_vec to node: NormalNoiseNode
<class 'mdp.nodes.NormalizeNode'>
Adding execute_data_vec to node: NormalizeNode
<class 'mdp.nodes.PCANode'>
Adding execute_data_vec to node: PCANode
<class 'more_nodes.PInvSwitchboard'>
Adding execute_data_vec to node: PInvSwitchboard
<class 'mdp.nodes.PerceptronClassifier'>
Adding execute_data_vec to node: PerceptronClassifier
<class 'more_nodes.PointwiseFunctionNode'>
Adding execute_data_vec to node: PointwiseFunctionNode
<class 'mdp.nodes.PolynomialExpansionNode'>
Adding execute_data_vec to node: PolynomialExpansionNode
<class 'mdp.nodes.QuadraticExpansionNode'>
Adding execute_data_vec to node: QuadraticExpansionNode
<class 'mdp.nodes.RBFExpansionNode'>
Adding execute_data_vec to node: RBFExpansionNode
<class 'mdp.nodes.RBMNode'>
Adding execute_data_vec to node: RBMNode
<class 'mdp.nodes.RBMWithLabelsNode'>
Adding execute_data_vec to node: RBMWithLabelsNode
<class 'more_nodes.RandomPermutationNode'>
Adding execute_data_vec to node: RandomPermutationNode
<class 'more_nodes.RandomizedMaskNode'>
Adding execute_data_vec to node: RandomizedMaskNode
<class 'mdp.nodes.SFA2Node'>
Adding execute_data_vec to node: SFA2Node
<class 'mdp.nodes.SFANode'>
Adding execute_data_vec to node: SFANode
<class 'more_nodes.SFAPCANode'>
Adding execute_data_vec to node: SFAPCANode
<class 'mdp.nodes.SignumClassifier'>
Adding execute_data_vec to node: SignumClassifier
<class 'mdp.nodes.SimpleMarkovClassifier'>
Adding execute_data_vec to node: SimpleMarkovClassifier
<class 'mdp.nodes.TDSEPNode'>
Adding execute_data_vec to node: TDSEPNode
<class 'mdp.nodes.TimeDelayNode'>
Adding execute_data_vec to node: TimeDelayNode
<class 'mdp.nodes.TimeDelaySlidingWindowNode'>
Adding execute_data_vec to node: TimeDelaySlidingWindowNode
<class 'mdp.nodes.TimeFramesNode'>
Adding execute_data_vec to node: TimeFramesNode
<class 'mdp.nodes.WhiteningNode'>
Adding execute_data_vec to node: WhiteningNode
<class 'mdp.nodes.XSFANode'>
Adding execute_data_vec to node: XSFANode
<class 'mdp.nodes.OneDimensionalHitParade'>
Not a node: _OneDimensionalHitParade
['PCANode', 'WhiteningNode', 'NIPALSNode', 'FastICANode', 'CuBICANode', 'TDSEPNode', 'JADENode', 'SFANode', 'SFA2Node', 'ISFANode', 'XSFANode', 'FDANode', 'FANode', 'RBMNode', 'RBMWithLabelsNode', 'GrowingNeuralGasNode', 'LLENode', 'HLLENode', 'LinearRegressionNode', 'QuadraticExpansionNode', 'PolynomialExpansionNode', 'RBFExpansionNode', 'GeneralExpansionNode', 'GrowingNeuralGasExpansionNode', '_expanded_dim', 'SignumClassifier', 'PerceptronClassifier', 'SimpleMarkovClassifier', 'DiscreteHopfieldClassifier', 'KMeansClassifier', 'NormalizeNode', 'GaussianClassifier', 'NearestMeanClassifier', 'KNNClassifier', 'EtaComputerNode', 'HitParadeNode', 'NoiseNode', 'NormalNoiseNode', 'TimeFramesNode', 'TimeDelayNode', 'TimeDelaySlidingWindowNode', 'CutoffNode', 'AdaptiveCutoffNode', 'HistogramNode', 'IdentityNode', '_OneDimensionalHitParade', 'Convolution2DNode', 'LibSVMClassifier']
Not a node: __all__
{'bytearray': <type 'bytearray'>, 'IndexError': <type 'exceptions.IndexError'>, 'all': <built-in function all>, 'help': Type help() for interactive help, or help(object) for help about object., 'vars': <built-in function vars>, 'SyntaxError': <type 'exceptions.SyntaxError'>, 'unicode': <type 'unicode'>, 'UnicodeDecodeError': <type 'exceptions.UnicodeDecodeError'>, 'isinstance': <built-in function isinstance>, 'copyright': Copyright (c) 2001-2010 Python Software Foundation.
All Rights Reserved.

Copyright (c) 2000 BeOpen.com.
All Rights Reserved.

Copyright (c) 1995-2001 Corporation for National Research Initiatives.
All Rights Reserved.

Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.
All Rights Reserved., 'NameError': <type 'exceptions.NameError'>, 'BytesWarning': <type 'exceptions.BytesWarning'>, 'dict': <type 'dict'>, 'input': <built-in function input>, 'oct': <built-in function oct>, 'bin': <built-in function bin>, 'SystemExit': <type 'exceptions.SystemExit'>, 'StandardError': <type 'exceptions.StandardError'>, 'format': <built-in function format>, 'repr': <built-in function repr>, 'sorted': <built-in function sorted>, 'False': False, 'RuntimeWarning': <type 'exceptions.RuntimeWarning'>, 'list': <type 'list'>, 'iter': <built-in function iter>, 'reload': <built-in function reload>, 'Warning': <type 'exceptions.Warning'>, '__package__': None, 'round': <built-in function round>, 'dir': <built-in function dir>, 'cmp': <built-in function cmp>, 'set': <type 'set'>, 'bytes': <type 'str'>, 'reduce': <built-in function reduce>, 'intern': <built-in function intern>, 'issubclass': <built-in function issubclass>, 'Ellipsis': Ellipsis, 'EOFError': <type 'exceptions.EOFError'>, 'locals': <built-in function locals>, 'BufferError': <type 'exceptions.BufferError'>, 'slice': <type 'slice'>, 'FloatingPointError': <type 'exceptions.FloatingPointError'>, 'sum': <built-in function sum>, 'getattr': <built-in function getattr>, 'abs': <built-in function abs>, 'exit': Use exit() or Ctrl-D (i.e. EOF) to exit, 'print': <built-in function print>, 'True': True, 'FutureWarning': <type 'exceptions.FutureWarning'>, 'ImportWarning': <type 'exceptions.ImportWarning'>, 'None': None, 'hash': <built-in function hash>, 'ReferenceError': <type 'exceptions.ReferenceError'>, 'len': <built-in function len>, 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands
    for supporting Python development.  See www.python.org for more information., 'frozenset': <type 'frozenset'>, '__name__': '__builtin__', 'ord': <built-in function ord>, 'super': <type 'super'>, 'TypeError': <type 'exceptions.TypeError'>, 'license': Type license() to see the full license text, 'KeyboardInterrupt': <type 'exceptions.KeyboardInterrupt'>, 'UserWarning': <type 'exceptions.UserWarning'>, 'filter': <built-in function filter>, 'range': <built-in function range>, 'staticmethod': <type 'staticmethod'>, 'SystemError': <type 'exceptions.SystemError'>, 'BaseException': <type 'exceptions.BaseException'>, 'pow': <built-in function pow>, 'RuntimeError': <type 'exceptions.RuntimeError'>, 'float': <type 'float'>, 'MemoryError': <type 'exceptions.MemoryError'>, 'StopIteration': <type 'exceptions.StopIteration'>, 'globals': <built-in function globals>, 'divmod': <built-in function divmod>, 'enumerate': <type 'enumerate'>, 'apply': <built-in function apply>, 'LookupError': <type 'exceptions.LookupError'>, 'open': <built-in function open>, 'quit': Use quit() or Ctrl-D (i.e. EOF) to exit, 'basestring': <type 'basestring'>, 'UnicodeError': <type 'exceptions.UnicodeError'>, 'zip': <built-in function zip>, 'hex': <built-in function hex>, 'long': <type 'long'>, 'next': <built-in function next>, 'ImportError': <type 'exceptions.ImportError'>, 'chr': <built-in function chr>, 'xrange': <type 'xrange'>, 'type': <type 'type'>, '__doc__': "Built-in functions, exceptions, and other objects.\n\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.", 'Exception': <type 'exceptions.Exception'>, 'tuple': <type 'tuple'>, 'UnicodeTranslateError': <type 'exceptions.UnicodeTranslateError'>, 'reversed': <type 'reversed'>, 'UnicodeEncodeError': <type 'exceptions.UnicodeEncodeError'>, 'IOError': <type 'exceptions.IOError'>, 'hasattr': <built-in function hasattr>, 'delattr': <built-in function delattr>, 'setattr': <built-in function setattr>, 'raw_input': <built-in function raw_input>, 'SyntaxWarning': <type 'exceptions.SyntaxWarning'>, 'compile': <built-in function compile>, 'ArithmeticError': <type 'exceptions.ArithmeticError'>, 'str': <type 'str'>, 'property': <type 'property'>, 'GeneratorExit': <type 'exceptions.GeneratorExit'>, 'int': <type 'int'>, '__import__': <built-in function __import__>, 'KeyError': <type 'exceptions.KeyError'>, 'coerce': <built-in function coerce>, 'PendingDeprecationWarning': <type 'exceptions.PendingDeprecationWarning'>, 'file': <type 'file'>, 'EnvironmentError': <type 'exceptions.EnvironmentError'>, 'unichr': <built-in function unichr>, 'id': <built-in function id>, 'OSError': <type 'exceptions.OSError'>, 'DeprecationWarning': <type 'exceptions.DeprecationWarning'>, 'min': <built-in function min>, 'UnicodeWarning': <type 'exceptions.UnicodeWarning'>, 'execfile': <built-in function execfile>, 'any': <built-in function any>, 'complex': <type 'complex'>, 'bool': <type 'bool'>, 'ValueError': <type 'exceptions.ValueError'>, 'NotImplemented': NotImplemented, 'map': <built-in function map>, 'buffer': <type 'buffer'>, 'max': <built-in function max>, 'object': <type 'object'>, 'TabError': <type 'exceptions.TabError'>, 'callable': <built-in function callable>, 'ZeroDivisionError': <type 'exceptions.ZeroDivisionError'>, 'eval': <built-in function eval>, '__debug__': True, 'IndentationError': <type 'exceptions.IndentationError'>, 'AssertionError': <type 'exceptions.AssertionError'>, 'classmethod': <type 'classmethod'>, 'UnboundLocalError': <type 'exceptions.UnboundLocalError'>, 'NotImplementedError': <type 'exceptions.NotImplementedError'>, 'AttributeError': <type 'exceptions.AttributeError'>, 'OverflowError': <type 'exceptions.OverflowError'>}
Not a node: __builtins__
None
Not a node: __doc__
restructuredtext en
Not a node: __docformat__
/home/escalafl/usr/lib/python2.6/site-packages/mdp/nodes/__init__.pyc
Not a node: __file__
mdp.nodes
Not a node: __name__
mdp.nodes
Not a node: __package__
['/home/escalafl/usr/lib/python2.6/site-packages/mdp/nodes']
Not a node: __path__
<function expanded_dim at 0x202ede8>
Not a node: _expanded_dim
<class 'mdp.hinet.ChannelSwitchboard'>
Adding execute_data_vec to (hinet) node: ChannelSwitchboard
<class 'mdp.hinet.CloneLayer'>
Adding execute_data_vec to (hinet) node: CloneLayer
<class 'mdp.hinet.DoubleRect2dSwitchboard'>
Adding execute_data_vec to (hinet) node: DoubleRect2dSwitchboard
<class 'mdp.hinet.DoubleRect2dSwitchboardException'>
Not a node: DoubleRect2dSwitchboardException
<class 'mdp.hinet.DoubleRhomb2dSwitchboard'>
Adding execute_data_vec to (hinet) node: DoubleRhomb2dSwitchboard
<class 'mdp.hinet.DoubleRhomb2dSwitchboardException'>
Not a node: DoubleRhomb2dSwitchboardException
<class 'mdp.hinet.switchboard_factory.FactoryDoubleRect2dSwitchboard'>
Adding execute_data_vec to (hinet) node: FactoryDoubleRect2dSwitchboard
<class 'mdp.hinet.switchboard_factory.FactoryDoubleRhomb2dSwitchboard'>
Adding execute_data_vec to (hinet) node: FactoryDoubleRhomb2dSwitchboard
<class 'mdp.hinet.switchboard_factory.FactoryExtensionChannelSwitchboard'>
Adding execute_data_vec to (hinet) node: FactoryExtensionChannelSwitchboard
<class 'mdp.hinet.switchboard_factory.FactoryRectangular2dSwitchboard'>
Adding execute_data_vec to (hinet) node: FactoryRectangular2dSwitchboard
<class 'mdp.hinet.FlowNode'>
Adding execute_data_vec to (hinet) node: FlowNode
<class 'mdp.hinet.htmlvisitor.HiNetHTMLVisitor'>
Not a node: HiNetHTMLVisitor
<class 'mdp.hinet.htmlvisitor.HiNetXHTMLVisitor'>
Not a node: HiNetXHTMLVisitor
<class 'mdp.hinet.Layer'>
Adding execute_data_vec to (hinet) node: Layer
<class 'mdp.hinet.switchboard.MeanInverseSwitchboard'>
Adding execute_data_vec to (hinet) node: MeanInverseSwitchboard
<class 'mdp.hinet.htmlvisitor.NewlineWriteFile'>
Not a node: NewlineWriteFile
<class 'mdp.hinet.Rectangular2dSwitchboard'>
Adding execute_data_vec to (hinet) node: Rectangular2dSwitchboard
<class 'mdp.hinet.Rectangular2dSwitchboardException'>
Not a node: Rectangular2dSwitchboardException
<class 'mdp.hinet.SameInputLayer'>
Adding execute_data_vec to (hinet) node: SameInputLayer
<class 'mdp.hinet.Switchboard'>
Adding execute_data_vec to (hinet) node: Switchboard
<class 'mdp.hinet.SwitchboardException'>
Not a node: SwitchboardException
['FlowNode', 'Layer', 'SameInputLayer', 'CloneLayer', 'Switchboard', 'SwitchboardException', 'ChannelSwitchboard', 'Rectangular2dSwitchboard', 'Rectangular2dSwitchboardException', 'DoubleRect2dSwitchboard', 'DoubleRect2dSwitchboardException', 'DoubleRhomb2dSwitchboard', 'DoubleRhomb2dSwitchboardException', 'HiNetHTMLVisitor', 'HiNetXHTMLVisitor', 'NewlineWriteFile', 'show_flow', 'get_2d_image_switchboard']
Not a node: __all__
{'bytearray': <type 'bytearray'>, 'IndexError': <type 'exceptions.IndexError'>, 'all': <built-in function all>, 'help': Type help() for interactive help, or help(object) for help about object., 'vars': <built-in function vars>, 'SyntaxError': <type 'exceptions.SyntaxError'>, 'unicode': <type 'unicode'>, 'UnicodeDecodeError': <type 'exceptions.UnicodeDecodeError'>, 'isinstance': <built-in function isinstance>, 'copyright': Copyright (c) 2001-2010 Python Software Foundation.
All Rights Reserved.

Copyright (c) 2000 BeOpen.com.
All Rights Reserved.

Copyright (c) 1995-2001 Corporation for National Research Initiatives.
All Rights Reserved.

Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.
All Rights Reserved., 'NameError': <type 'exceptions.NameError'>, 'BytesWarning': <type 'exceptions.BytesWarning'>, 'dict': <type 'dict'>, 'input': <built-in function input>, 'oct': <built-in function oct>, 'bin': <built-in function bin>, 'SystemExit': <type 'exceptions.SystemExit'>, 'StandardError': <type 'exceptions.StandardError'>, 'format': <built-in function format>, 'repr': <built-in function repr>, 'sorted': <built-in function sorted>, 'False': False, 'RuntimeWarning': <type 'exceptions.RuntimeWarning'>, 'list': <type 'list'>, 'iter': <built-in function iter>, 'reload': <built-in function reload>, 'Warning': <type 'exceptions.Warning'>, '__package__': None, 'round': <built-in function round>, 'dir': <built-in function dir>, 'cmp': <built-in function cmp>, 'set': <type 'set'>, 'bytes': <type 'str'>, 'reduce': <built-in function reduce>, 'intern': <built-in function intern>, 'issubclass': <built-in function issubclass>, 'Ellipsis': Ellipsis, 'EOFError': <type 'exceptions.EOFError'>, 'locals': <built-in function locals>, 'BufferError': <type 'exceptions.BufferError'>, 'slice': <type 'slice'>, 'FloatingPointError': <type 'exceptions.FloatingPointError'>, 'sum': <built-in function sum>, 'getattr': <built-in function getattr>, 'abs': <built-in function abs>, 'exit': Use exit() or Ctrl-D (i.e. EOF) to exit, 'print': <built-in function print>, 'True': True, 'FutureWarning': <type 'exceptions.FutureWarning'>, 'ImportWarning': <type 'exceptions.ImportWarning'>, 'None': None, 'hash': <built-in function hash>, 'ReferenceError': <type 'exceptions.ReferenceError'>, 'len': <built-in function len>, 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands
    for supporting Python development.  See www.python.org for more information., 'frozenset': <type 'frozenset'>, '__name__': '__builtin__', 'ord': <built-in function ord>, 'super': <type 'super'>, 'TypeError': <type 'exceptions.TypeError'>, 'license': Type license() to see the full license text, 'KeyboardInterrupt': <type 'exceptions.KeyboardInterrupt'>, 'UserWarning': <type 'exceptions.UserWarning'>, 'filter': <built-in function filter>, 'range': <built-in function range>, 'staticmethod': <type 'staticmethod'>, 'SystemError': <type 'exceptions.SystemError'>, 'BaseException': <type 'exceptions.BaseException'>, 'pow': <built-in function pow>, 'RuntimeError': <type 'exceptions.RuntimeError'>, 'float': <type 'float'>, 'MemoryError': <type 'exceptions.MemoryError'>, 'StopIteration': <type 'exceptions.StopIteration'>, 'globals': <built-in function globals>, 'divmod': <built-in function divmod>, 'enumerate': <type 'enumerate'>, 'apply': <built-in function apply>, 'LookupError': <type 'exceptions.LookupError'>, 'open': <built-in function open>, 'quit': Use quit() or Ctrl-D (i.e. EOF) to exit, 'basestring': <type 'basestring'>, 'UnicodeError': <type 'exceptions.UnicodeError'>, 'zip': <built-in function zip>, 'hex': <built-in function hex>, 'long': <type 'long'>, 'next': <built-in function next>, 'ImportError': <type 'exceptions.ImportError'>, 'chr': <built-in function chr>, 'xrange': <type 'xrange'>, 'type': <type 'type'>, '__doc__': "Built-in functions, exceptions, and other objects.\n\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.", 'Exception': <type 'exceptions.Exception'>, 'tuple': <type 'tuple'>, 'UnicodeTranslateError': <type 'exceptions.UnicodeTranslateError'>, 'reversed': <type 'reversed'>, 'UnicodeEncodeError': <type 'exceptions.UnicodeEncodeError'>, 'IOError': <type 'exceptions.IOError'>, 'hasattr': <built-in function hasattr>, 'delattr': <built-in function delattr>, 'setattr': <built-in function setattr>, 'raw_input': <built-in function raw_input>, 'SyntaxWarning': <type 'exceptions.SyntaxWarning'>, 'compile': <built-in function compile>, 'ArithmeticError': <type 'exceptions.ArithmeticError'>, 'str': <type 'str'>, 'property': <type 'property'>, 'GeneratorExit': <type 'exceptions.GeneratorExit'>, 'int': <type 'int'>, '__import__': <built-in function __import__>, 'KeyError': <type 'exceptions.KeyError'>, 'coerce': <built-in function coerce>, 'PendingDeprecationWarning': <type 'exceptions.PendingDeprecationWarning'>, 'file': <type 'file'>, 'EnvironmentError': <type 'exceptions.EnvironmentError'>, 'unichr': <built-in function unichr>, 'id': <built-in function id>, 'OSError': <type 'exceptions.OSError'>, 'DeprecationWarning': <type 'exceptions.DeprecationWarning'>, 'min': <built-in function min>, 'UnicodeWarning': <type 'exceptions.UnicodeWarning'>, 'execfile': <built-in function execfile>, 'any': <built-in function any>, 'complex': <type 'complex'>, 'bool': <type 'bool'>, 'ValueError': <type 'exceptions.ValueError'>, 'NotImplemented': NotImplemented, 'map': <built-in function map>, 'buffer': <type 'buffer'>, 'max': <built-in function max>, 'object': <type 'object'>, 'TabError': <type 'exceptions.TabError'>, 'callable': <built-in function callable>, 'ZeroDivisionError': <type 'exceptions.ZeroDivisionError'>, 'eval': <built-in function eval>, '__debug__': True, 'IndentationError': <type 'exceptions.IndentationError'>, 'AssertionError': <type 'exceptions.AssertionError'>, 'classmethod': <type 'classmethod'>, 'UnboundLocalError': <type 'exceptions.UnboundLocalError'>, 'NotImplementedError': <type 'exceptions.NotImplementedError'>, 'AttributeError': <type 'exceptions.AttributeError'>, 'OverflowError': <type 'exceptions.OverflowError'>}
Not a node: __builtins__
Hierarchical Networks Package.

This package makes it possible to construct graph-like Node structures,
especially hierarchical networks.

The most important building block is the new Layer node, which works as an
horizontal version of flow. It encapsulates a list of Nodes, which are trained
and executed in parallel.
For example we can take two Nodes with 100 dimensional input to
construct a layer with a 200 dimensional input. The first half of the input
data is automatically fed into the first Node, the second half into the second
Node.

Since one might also want to use Flows (i.e. vertical stacks of Nodes) in a
Layer, a wrapper class for Nodes is provided.
The FlowNode class wraps any Flow into a Node, which can then be used like any
other Node. Together with the Layer this allows you to combine Nodes both
horizontally and vertically. Thereby one can in principle realize
any feed-forward network topology.

For a hierarchical networks one might want to route the different parts of the
data to different Nodes in a Layer in complicated ways. This is done by a
Switchboard that handles all the routing.
Defining the routing manually can be quite tedious, so one can derive subclasses
for special routing situations. One such subclass for 2d image data is provided.
It maps the data according to rectangular overlapping 2d input areas. One can
then feed the output into a Layer and each Node will get the correct input.

Not a node: __doc__
/home/escalafl/usr/lib/python2.6/site-packages/mdp/hinet/__init__.pyc
Not a node: __file__
mdp.hinet
Not a node: __name__
mdp.hinet
Not a node: __package__
['/home/escalafl/usr/lib/python2.6/site-packages/mdp/hinet']
Not a node: __path__
<module 'sys' (built-in)>
Not a node: _sys
<function fixup_namespace at 0x1e8fc08>
Not a node: fixup_namespace
<module 'mdp.hinet.flownode' from '/home/escalafl/usr/lib/python2.6/site-packages/mdp/hinet/flownode.pyc'>
Not a node: flownode
<function get_2d_image_switchboard at 0x22faed8>
Not a node: get_2d_image_switchboard
<module 'mdp.hinet.htmlvisitor' from '/home/escalafl/usr/lib/python2.6/site-packages/mdp/hinet/htmlvisitor.pyc'>
Not a node: htmlvisitor
<module 'mdp.hinet.layer' from '/home/escalafl/usr/lib/python2.6/site-packages/mdp/hinet/layer.pyc'>
Not a node: layer
<function show_flow at 0x22f9668>
Not a node: show_flow
<module 'mdp.hinet.switchboard' from '/home/escalafl/usr/lib/python2.6/site-packages/mdp/hinet/switchboard.pyc'>
Not a node: switchboard
<module 'mdp.hinet.switchboard_factory' from '/home/escalafl/usr/lib/python2.6/site-packages/mdp/hinet/switchboard_factory.pyc'>
Not a node: switchboard_factory
LOADING INPUT INFORMATION
SystemParameters.ParamsSFALayer.ord_node_class is: None
SystemParameters.ParamsSFALayer.ord_args is: {}
*******************************************************************
********    Creating Void Network            ******************
*******************************************************************
******** Setting Layer L0 Parameters          *********************
*******************************************************************
********    Creating One-Layer Linear SFA Network            ******************
*******************************************************************
******** Setting Layer L0 Parameters          *********************
*******************************************************************
******** Creating Linear 4L SFA Network          ******************
*******************************************************************
******** Setting Layer L0 Parameters          *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214910> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L1 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x22149d0> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L2 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214a10> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L3 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFASuperNode object at 0x2214a50> contains 'None' fields:  ['clip_func', 'ord_node_class', 'node_list', 'clip_inv_func']
******** Setting Layer L4 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFASuperNode object at 0x2214990> contains 'None' fields:  ['clip_func', 'ord_node_class', 'node_list', 'clip_inv_func']
*******************************************************************
******** Creating Non-Linear 4L SFA Network      ******************
*******************************************************************
******** Setting Layer NL0 Parameters          ********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214b50> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer NL1 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214d10> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer NL2 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214d50> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer NL3 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFASuperNode object at 0x2214dd0> contains 'None' fields:  ['clip_func', 'ord_node_class', 'node_list', 'clip_inv_func']
******** Setting Layer NL4 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFASuperNode object at 0x2214d90> contains 'None' fields:  ['clip_func', 'ord_node_class', 'node_list', 'clip_inv_func']
*******************************************************************
******** Creating Linear Thin 6L SFA Network          ******************
*******************************************************************
******** Setting Layer L0 Parameters          *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214ed0> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L1 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214f50> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L2 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214f90> contains 'None' fields:  ['clip_func', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L3 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214fd0> contains 'None' fields:  ['clip_func', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
******** Setting Layer L4 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2214f10> contains 'None' fields:  ['clip_func', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
******** Setting Layer L5 Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218090> contains 'None' fields:  ['clip_func', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
*******************************************************************
******** Creating Non-Linear Thin 6L SFA Network ******************
*******************************************************************
*******************************************************************
******** Creating Linear Ultra Thin 11L SFA Network ***************
*******************************************************************
******** Copying Layer L0 Parameters from  pSFATLayerL0    ********
******** Setting Ultra Thin Layer L1 H Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218310> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Ultra Thin Layer L1 V Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218390> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L2 H Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x22183d0> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L2 V Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218410> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'layer_number', 'ord_node_class', 'node_list', 'clip_inv_func', 'nx_value']
******** Setting Layer L3 H Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218450> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
******** Setting Layer L3 V Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218490> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
******** Setting Layer L4 H Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x22184d0> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
******** Setting Layer L4 V Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218510> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
******** Setting Layer L5 H Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218550> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
******** Setting Layer L5 V Parameters *********************
Warning!!! object <SystemParameters.ParamsSFALayer object at 0x2218590> contains 'None' fields:  ['clip_func', 'red_node_class', 'ny_value', 'clip_inv_func', 'nx_value', 'layer_number', 'ord_node_class', 'node_list']
linearPCANetwork4L, L0-3_PCA_out_dim =  [12, 52, 229, 1000]
WARNING!!!! Overriding output_dimensionalities of PCA Network, to fit SFA Network or exceed it
linearPCANetworkU11L, L0-10_PCA_out_dim =  [13, 20, 35, 60, 100, 120, 120, 120, 120, 120, 120]
IEVMLRecNetworkU11L L0-10_SFA_out_dim =  [22, 35, 45, 60, 60, 60, 60, 60, 60, 60, 60]
IEMNetworkU11L L0-10_SFA_out_dim =  [13, 20, 35, 60, 60, 60, 60, 60, 60, 60, 60]
*******************************************************************
******** Creating Non-Linear Ultra Thin 11L SFA Network ******************
*******************************************************************
Unknown host, but /local/escalafl available
******** Setting Training Information Parameters for Gender **********
Warning!!! object <SystemParameters.ParamsInput object at 0x2222b50> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Gender  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2218b90> contains 'None' fields:  ['obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
****** Setting Seen Id Test Information Parameters for Gender ********
Warning!!! object <SystemParameters.ParamsInput object at 0x2218b10> contains 'None' fields:  ['train_mode']
***** Setting Seen Id Sequence Parameters for Gender ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2218910> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
** Setting New Id Test Information Parameters for Gender **********
Warning!!! object <SystemParameters.ParamsInput object at 0x2214810> contains 'None' fields:  ['train_mode']
******** Setting New Id Data Parameters ******************************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2214450> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
******** Setting Train Information Parameters for Identity ***********
Warning!!! object <SystemParameters.ParamsInput object at 0x2222b90> contains 'None' fields:  ['train_mode']
***** Setting Train Sequence Parameters for Identity *****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2222bd0> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting Seen Id Information Parameters for Identity *********
Warning!!! object <SystemParameters.ParamsInput object at 0x2222c10> contains 'None' fields:  ['train_mode']
******** Setting Seen Id Sequence Parameters for Identity ************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2214c90> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting New Id Information Parameters for Identity **********
Warning!!! object <SystemParameters.ParamsInput object at 0x2214390> contains 'None' fields:  ['train_mode']
******** Setting New Id Sequence Parameters for Identity *************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2218990> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting Train Information Parameters for Angle **************
Warning!!! object <SystemParameters.ParamsInput object at 0x2222c90> contains 'None' fields:  ['train_mode']
***** Setting Train Sequence Parameters for Angle ********************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2222cd0> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting Seen Id Information Parameters for Angle ************
Warning!!! object <SystemParameters.ParamsInput object at 0x2222d10> contains 'None' fields:  ['train_mode']
******** Setting Seen Id Sequence Parameters for Angle ***************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2222d50> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting New Id Information Parameters for Angle *************
Warning!!! object <SystemParameters.ParamsInput object at 0x2222d90> contains 'None' fields:  ['train_mode']
******** Setting New Id Sequence Parameters for Angle ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2222dd0> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for Translation X ******
Warning!!! object <SystemParameters.ParamsInput object at 0x2222e50> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for TransX  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2222e90> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Seen ID Information Parameters for Translation X *******
Warning!!! object <SystemParameters.ParamsInput object at 0x2222f90> contains 'None' fields:  ['train_mode']
******** Setting Seen Id Data Parameters for TransX  *****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2222fd0> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting New Id Information Parameters for Translation X *****
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c050> contains 'None' fields:  ['train_mode']
******** Setting Seen Id Data Parameters for TransX  *****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2222f50> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for Age ******
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c110> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Age  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c150> contains 'None' fields:  ['obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting Seen Id Test Information Parameters for Age ******
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c190> contains 'None' fields:  ['train_mode']
******** Setting Seen Id Data Parameters for Age  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c1d0> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting New Id Test Information Parameters for Age ******
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c210> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Age  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c250> contains 'None' fields:  ['train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting Training Information Parameters for Real Translation X ******
BLOCK SIZE = 708
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c2d0> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real TransX  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2218a90> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Seen ID Information Parameters for Real Translation X *******
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c390> contains 'None' fields:  ['train_mode']
******** Setting Seen Id Data Parameters for Real TransX  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c3d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting New Id Information Parameters for Real Translation X *****
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c410> contains 'None' fields:  ['train_mode']
******** Setting New ID Data Parameters for Real TransX  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c450> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for Real Translation Y ******
BLOCK SIZE = 800
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c4d0> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real TransY  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c510> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Seen ID Information Parameters for Real Translation Y *******
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c590> contains 'None' fields:  ['train_mode']
******** Setting Seen Id Data Parameters for Real TransY  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c310> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
******** Setting New Id Information Parameters for Real Translation Y *****
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c5d0> contains 'None' fields:  ['train_mode']
******** Setting New ID Data Parameters for Real TransY  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c610> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
Studienprojekt. Scale estimation datasets. By Jan, Stephan and Alberto 
***** Setting Training Information Parameters for Scale ******
BLOCK SIZE = 1200
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c690> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Scale  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c6d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting SeenId Information Parameters for Scale ******
BLOCK SIZE = 600
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c750> contains 'None' fields:  ['train_mode']
******** Setting SeenId Data Parameters for Real Scale  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2218a10> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting NewId Information Parameters for Scale ******
BLOCK SIZE = 200
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c790> contains 'None' fields:  ['train_mode']
******** Setting NewId Data Parameters for Real Scale  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c7d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
Studienprojekt. Illumination estimation datasets. By Jan and Stephan and Alberto 
***** Setting Training Information Parameters for Illumination ******
BLOCK SIZE = 220
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c350> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Illumination  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c890> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
BLOCK SIZE = 50
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c810> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Illumination  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c8d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
BLOCK SIZE = 40
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9c950> contains 'None' fields:  ['train_mode']
******** Setting Testing Data Parameters for Real Illumination  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c990> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
Studienprojekt. Rotation estimation datasets. By Jan and Stephan and Alberto 
***** Setting Training Information Parameters for Rotation ******
BLOCK SIZE = 280
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9ca10> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Rotation  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9ca50> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
BLOCK SIZE = 60
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9ca90> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Rotation  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9cad0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
BLOCK SIZE = 50
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9cb10> contains 'None' fields:  ['train_mode']
******** Setting Testing Data Parameters for Real Illumination  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9cb50> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for Face ******
BLOCK SIZE = 12000
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9cbd0> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Face  ****************
 sSeq.subimage_first_row = [ 38.74143769  33.83476536  40.11733445 ...,  23.76573613  23.26944834
  46.9433079 ]
sSeq.pixelsampling_x [ 0.848275    0.92096644  0.82789134 ...,  1.0560901   0.71534896
  1.07420123]
sSeq.translations_x [-11.          13.          19.         ..., -27.54774209  32.44001575
  37.21771382]
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9cc10> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Seenid Information Parameters for Face ******
BLOCK SIZE = 8000
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9cd10> contains 'None' fields:  ['train_mode']
******** Setting SeenID Data Parameters for Real Face  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c550> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Newid Information Parameters for Face ******
BLOCK SIZE = 2000
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9cd50> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Face  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9cd90> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for RObject ******
totaling 0 images
BLOCK SIZE = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
BLOCK SIZES = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[]
[]
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9ce10> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Object  ****************
 sSeq.subimage_first_row = 2.0
sSeq.pixelsampling_x 1.5
sSeq.translations_x []
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9ce50> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Seenid Information Parameters for RObject ******
totaling 0 images
BLOCK SIZE = [0 0 0 0 0 0 0 0 0 0]
BLOCK SIZES = [0 0 0 0 0 0 0 0 0 0]
[]
[]
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9ce90> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Object  ****************
 sSeq.subimage_first_row = 2.0
sSeq.pixelsampling_x 1.5
sSeq.translations_x []
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9ced0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for RObject ******
totaling 0 images
BLOCK SIZE = [0 0 0 0 0 0 0 0 0 0]
BLOCK SIZES = [0 0 0 0 0 0 0 0 0 0]
[]
[]
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9cf50> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Object  ****************
 sSeq.subimage_first_row = 2.0
sSeq.pixelsampling_x 1.5
sSeq.translations_x []
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9cf90> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Project: Processing natural images with SFA,  ******
***** Image Patches courtesy of Niko Wilbert ******
***** Setting Training Information Parameters for RawNatural ******
totaling 4000 samples
BLOCK SIZE = 1
Warning!!! object <SystemParameters.ParamsInput object at 0x2d9cfd0> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for RawNatural  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6050> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'translations_y', 'translations_x', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for RawNatural ******
totaling 1000 samples
BLOCK SIZE = 1
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6090> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Natural  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a60d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'translations_y', 'translations_x', 'obj_stds', 'filter', 'load_data']
***** Project: Integration of RBM and SFA,  ******
***** Setting Training Information Parameters for Natural ******
binary string read:   N    @   
Loaded header:  (666, 19999, 5000, 64, -1)
totaling 4000 samples
BLOCK SIZE = 1
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6150> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Natural  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a61d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'translations_y', 'translations_x', 'obj_stds', 'filter', 'load_data']
***** Setting Newid Information Parameters for Natural ******
binary string read:   N    @   
Loaded header:  (666, 19999, 5000, 64, -1)
totaling 1000 images
BLOCK SIZE = 1
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6210> contains 'None' fields:  ['train_mode']
******** Setting Newid Data Parameters for Natural ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6290> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'translations_y', 'translations_x', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for RFaceCentering******
BLOCK SIZE = 1200
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6390> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a63d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting SeenId Information Parameters for RFaceCentering******
BLOCK SIZE = 1500
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6410> contains 'None' fields:  ['train_mode']
******** Setting Seenid Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9cc90> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting NewId Information Parameters for RFaceCentering******
BLOCK SIZE = 200
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6490> contains 'None' fields:  ['train_mode']
******** Setting Seenid Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a64d0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Training Information Parameters for Real Eye Translation X ******
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6550> contains 'None' fields:  ['train_mode']
******** Setting Training Data Parameters for Real Eye TransX  ****************
REyeTans X Dx in (-10, 10) Dy in (-10, 10), sampling in (67.500000, 97.500000)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9ccd0> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Seenid Information Parameters for Real Eye Translation X ******
Warning!!! object <SystemParameters.ParamsInput object at 0x47a65d0> contains 'None' fields:  ['train_mode']
******** Setting Seenid Data Parameters for Real Eye TransX  ****************
REyeTans X Dx in (-10, 10) Dy in (-10, 10), sampling in (67.500000, 97.500000)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6610> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting Newid Information Parameters for Real Eye Translation X ******
Warning!!! object <SystemParameters.ParamsInput object at 0x47a6650> contains 'None' fields:  ['train_mode']
******** Setting Newid Data Parameters for Real Eye TransX  ****************
REyeTans X Dx in (-10, 10) Dy in (-10, 10), sampling in (67.500000, 97.500000)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6690> contains 'None' fields:  ['background_type', 'train_mode', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
***** Setting information Parameters for RFaceCentering******
BLOCK SIZE = 600
******** Setting Training Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6910> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
;)
***** Setting information Parameters for RFaceCentering******
BLOCK SIZE = 600
***** Setting information Parameters for RFaceCentering******
BLOCK SIZE = 600
***** Setting information Parameters for RFaceCentering******
BLOCK SIZE = 600
******** Setting Training Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a68d0> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
******** Setting Training Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6a90> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
******** Setting Training Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6910> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting information Parameters for RFaceCentering******
BLOCK SIZE = 200
******** Setting Training Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6ad0> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting information Parameters for RFaceCentering******
BLOCK SIZE = 200
******** Setting Training Data Parameters for Real Face Centering****************
Face Centering. Dx in (-45, 45) Dy in (-19, 19), sampling in (450.000000, 1100.000000, 50)
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6c10> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting Information Parameters for Real Translation X ******
BLOCK SIZE = 200
******** Setting Training Data Parameters for Real TransX  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2d9c910> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
128
***** Setting Information Parameters for Real Translation X ******
BLOCK SIZE = 200
******** Setting Training Data Parameters for Real TransX  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a68d0> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
128
***** Setting Information Parameters for Real Translation X ******
BLOCK SIZE = 100
******** Setting Training Data Parameters for Real TransX  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6450> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
128
***** Setting Training Information Parameters for Real Translation Y ******
BLOCK SIZE = 250
******** Setting Training Data Parameters for Real TransY  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6cd0> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
128
***** Setting Training Information Parameters for Real Translation Y ******
BLOCK SIZE = 250
******** Setting Training Data Parameters for Real TransY  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x2218890> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
128
***** Setting Training Information Parameters for Real Translation Y ******
BLOCK SIZE = 125
******** Setting Training Data Parameters for Real TransY  ****************
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6e10> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter', 'load_data']
128
GTSRBFunc not present or disabled
posXseed= 1112223336
posXseed= 1112223336
:)***********************
***** Setting Information Parameters for Real Translation XYScale ******
number of input files= 30000
number of iSeq.ids= 30000
BLOCK SIZE = 1200
******** Setting Training Data Parameters for Real TransX  ****************
sSeq.translations_x= [-45.         -44.99849997 -44.99699995 ...,  44.99699995  44.99849997  45.        ]
len( sSeq.translations_x)= 60000
Var in trans X is: 675.022500375
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6b10> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting Information Parameters for Real Translation XYScale ******
number of input files= 25000
number of iSeq.ids= 25000
BLOCK SIZE = 1000
******** Setting Training Data Parameters for Real TransX  ****************
sSeq.translations_x= [-45.         -44.99819996 -44.99639993 ...,  44.99639993  44.99819996  45.        ]
len( sSeq.translations_x)= 50000
Var in trans X is: 675.02700054
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x47a6d50> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
***** Setting Information Parameters for Real Translation XYScale ******
number of input files= 9000
number of iSeq.ids= 9000
BLOCK SIZE = 360
******** Setting Training Data Parameters for Real TransX  ****************
sSeq.translations_x= [-45.         -44.99499972 -44.98999944 ...,  44.98999944  44.99499972  45.        ]
len( sSeq.translations_x)= 18000
Var in trans X is: 675.075004167
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x6732210> contains 'None' fields:  ['background_type', 'obj_avgs', 'rotation', 'obj_stds', 'filter']
Orig iSeenidRTransXYScale.correct_labels= [-45.         -44.99819996 -44.99639993 ...,  44.99639993  44.99819996  45.        ]
Orig len(iSeenidRTransXYScale.correct_labels)= 50000
Orig len(iSeenidRTransXYScale.correct_classes)= 50000
all_classes= [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]
avg_labels= [-44.10088202 -42.30084602 -40.50081002 -38.70077402 -36.90073801
 -35.10070201 -33.30066601 -31.50063001 -29.70059401 -27.90055801
 -26.10052201 -24.30048601 -22.50045001 -20.70041401 -18.90037801
 -17.10034201 -15.30030601 -13.50027001 -11.700234    -9.900198    -8.100162
  -6.300126    -4.50009     -2.700054    -0.900018     0.900018     2.700054
   4.50009      6.300126     8.100162     9.900198    11.700234
  13.50027001  15.30030601  17.10034201  18.90037801  20.70041401
  22.50045001  24.30048601  26.10052201  27.90055801  29.70059401
  31.50063001  33.30066601  35.10070201  36.90073801  38.70077402
  40.50081002  42.30084602  44.10088202]
num_images_per_cluster_used_FGNet= 427
num_images_per_cluster_used_INIBilder= 71
num_images_per_cluster_used_MORPH_FGNet= 0
***** Setting Information Parameters for Real Translation XYScale ******
BLOCK SIZE = 1000
******** Setting Training Data Parameters for Real Age  ****************
GSP: sSeq.translations_x= [ 1  0  0 ...,  0  0 -1]
Mean in correct_labels is: 32.8826333333
Var in correct_labels is: 121.653458399
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x817e390> contains 'None' fields:  ['background_type', 'filter']
***** Setting Information Parameters for Real Translation XYScale ******
BLOCK SIZE = 200
******** Setting Training Data Parameters for Real Age  ****************
GSP: sSeq.translations_x= [ 1  0  1 ...,  0  0 -1]
Mean in correct_labels is: 32.8856666667
Var in correct_labels is: 121.759927889
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x8182d90> contains 'None' fields:  ['background_type', 'filter']
***** Setting Information Parameters for Real Translation XYScale ******
BLOCK SIZE = 200
******** Setting Training Data Parameters for Real Age  ****************
GSP: sSeq.translations_x= [0 0 0 ..., 0 0 0]
Mean in correct_labels is: 32.8818333333
Var in correct_labels is: 121.666869972
Warning!!! object <SystemParameters.ParamsDataLoading object at 0x8182e50> contains 'None' fields:  ['background_type', 'filter']
Using mdp version: 3.2 file: /home/escalafl/usr/lib/python2.6/site-packages/mdp/__init__.pyc
/home/escalafl/workspace4/cuicuilco_MDP3.2/src/GenerateSystemParameters.pyc
Apparent command line arguments:  ['cuicuilco_run.py', '--EnableDisplay=0', '--CacheAvailable=1', '--NetworkCacheReadDir=/local/tmp/escalafl/Alberto/SavedNetworks', '--NetworkCacheWriteDir=None', '--NodeCacheReadDir=/local/tmp/escalafl/Alberto/SavedNodes', '--NodeCacheWriteDir=/local/tmp/escalafl/Alberto/SavedNodes', '--SaveSubimagesTraining=0', '--SaveAverageSubimageTraining=0', '--NumFeaturesSup=17', '--SaveSorted_AE_GaussNewid=0', '--SaveSortedIncorrectClassGaussNewid=0', '--ComputeSlowFeaturesNewidAcrossNet=0', '--UseFilter=0', '--EnableKNN=0', '--kNN_k=5', '--EnableNCC=0', '--EnableSVM=1', '--SVM_C=0.500000', '--SVM_gamma=0.500000', '--EnableLR=0', '--AskNetworkLoading=0', '--LoadNetworkNumber=-1', '--NParallel=2', '--EnableScheduler=0', '--EstimateExplainedVarWithInverse=0', '--EstimateExplainedVarWithKNN_k=0', '--EstimateExplainedVarWithKNNLinApp=0', '--EstimateExplainedVarLinGlobal_N=0', '--AddNormalizationNode=0', '--MakeLastPCANodeWhithening=0', '--FeatureCutOffLevel=0.0', '--ExportDataToLibsvm=0']
opts= [('--EnableDisplay', '0'), ('--CacheAvailable', '1'), ('--NetworkCacheReadDir', '/local/tmp/escalafl/Alberto/SavedNetworks'), ('--NetworkCacheWriteDir', 'None'), ('--NodeCacheReadDir', '/local/tmp/escalafl/Alberto/SavedNodes'), ('--NodeCacheWriteDir', '/local/tmp/escalafl/Alberto/SavedNodes'), ('--SaveSubimagesTraining', '0'), ('--SaveAverageSubimageTraining', '0'), ('--NumFeaturesSup', '17'), ('--SaveSorted_AE_GaussNewid', '0'), ('--SaveSortedIncorrectClassGaussNewid', '0'), ('--ComputeSlowFeaturesNewidAcrossNet', '0'), ('--UseFilter', '0'), ('--EnableKNN', '0'), ('--kNN_k', '5'), ('--EnableNCC', '0'), ('--EnableSVM', '1'), ('--SVM_C', '0.500000'), ('--SVM_gamma', '0.500000'), ('--EnableLR', '0'), ('--AskNetworkLoading', '0'), ('--LoadNetworkNumber', '-1'), ('--NParallel', '2'), ('--EnableScheduler', '0'), ('--EstimateExplainedVarWithInverse', '0'), ('--EstimateExplainedVarWithKNN_k', '0'), ('--EstimateExplainedVarWithKNNLinApp_k', '0'), ('--EstimateExplainedVarLinGlobal_N', '0'), ('--AddNormalizationNode', '0'), ('--MakeLastPCANodeWhithening', '0'), ('--FeatureCutOffLevel', '0.0'), ('--ExportDataToLibsvm', '0')]
args= []
Setting enable_display to False
Setting cache_available to True
Setting network_cache_read_dir to /local/tmp/escalafl/Alberto/SavedNetworks
Setting network_cache_write_dir to None
Setting node_cache_read_dir to /local/tmp/escalafl/Alberto/SavedNodes
Setting node_cache_write_dir to /local/tmp/escalafl/Alberto/SavedNodes
Setting save_subimages_training to False
Setting save_average_subimage_training to False
Setting  to Setting save_sorted_AE_Gauss_newid to False
Setting save_sorted_incorrect_class_Gauss_newid to False
Setting compute_slow_features_newid_across_net to 0
Setting use_filter to 0
Setting enable_kNN to False
Setting kNN_k to 5
Setting enable_NCC to False
Setting enable_svm to 1
Setting svm_C to 0.5
Setting svm_gamma to 0.5
Setting enable_lr to 0
Setting ask_network_loading to 0
Setting load_network_number to -1
Setting n_parallel to 2
Setting enable_scheduler to 0
Setting estimate_explained_var_with_inverse to False
Setting estimate_explained_var_with_kNN_k to 0
Setting estimate_explained_var_with_kNN_lin_app_k to 0
Setting estimate_explained_var_linear_global_N to 0
Setting add_normalization_node to False
Setting make_last_PCA_node_whithening to False
Setting feature_cut_off_level to 0.0
Setting export_data_to_libsvm to False
sSeq [[<SystemParameters.ParamsDataLoading object at 0x47a6b10>]]
sSeq_vect [<SystemParameters.ParamsDataLoading object at 0x47a6b10>]
sSeq.translations_x= [-45.         -44.99849997 -44.99699995 ...,  44.99699995  44.99849997  45.        ]
128.0 SCALE!
sSeq <SystemParameters.ParamsDataLoading object at 0x47a6d50>
sSeq.translations_x= [-45.         -44.99819996 -44.99639993 ...,  44.99639993  44.99819996  45.        ]
128.0 SCALE!
sSeq [[<SystemParameters.ParamsDataLoading object at 0x6732210>]]
sSeq_vect [<SystemParameters.ParamsDataLoading object at 0x6732210>]
sSeq.translations_x= [-45.         -44.99499972 -44.98999944 ...,  44.98999944  44.99499972  45.        ]
128.0 SCALE!
201 networks found:
[0] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1312292154
[1] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1312294355
[2] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1312299250
[3] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for GTSRB_Resized images_1312372569
[4] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for GTSRB_Resized images_1312380408
[5] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for GTSRB_Resized images_1312381443
[6] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for GTSRB_Resized images_1312383434
[7] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for GTSRB_Resized images_1312384708
[8] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for GTSRB_Resized images_1312385546
[9] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for GTSRB_1312386323
[10] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331724365
[11] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331728232
[12] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331731019
[13] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331743599
[14] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331827136
[15] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331828741
[16] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331839173
[17] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1331915290
[18] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1332088640
[19] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1332164502
[20] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1332867365
[21] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338559865
[22] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338813874
[23] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338821434
[24] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338828302
[25] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338896180
[26] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338901754
[27] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338907754
[28] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338915464
[29] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1338982620
[30] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339000675
[31] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339166190
[32] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339501287
[33] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339509794
[34] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339515678
[35] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339581738
[36] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339595963
[37] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339606483
[38] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339617009
[39] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1339674335
[40] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1341924366
[41] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1341926700
[42] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1341927650
[43] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1341930324
[44] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1341938114
[45] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342004206
[46] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342016469
[47] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342020104
[48] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342021771
[49] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342097124
[50] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342099975
[51] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342109264
[52] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342109594
[53] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342133467
[54] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkSFA 1 Layer Linear Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342450662
[55] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkSFA 1 Layer Linear Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342451757
[56] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342451958
[57] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342623331
[58] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342626690
[59] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkSFA 1 Layer Linear Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342698256
[60] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkSFA 1 Layer Linear Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342701109
[61] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342703115
[62] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342708170
[63] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342718881
[64] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342777037
[65] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1342815135
[66] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1343135509
[67] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1343651950
[68] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1343746832
[69] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1343877008
[70] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1345473876
[71] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1345567070
[72] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1345810184
[73] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1348882599
[74] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1349016357
[75] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1349207870
[76] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1349473746
[77] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1349698777
[78] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1349716700
[79] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1349797574
[80] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1349973031
[81] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350038780
[82] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350044403
[83] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350049836
[84] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350050554
[85] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350050561
[86] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350056125
[87] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350401258
[88] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1350402311
[89] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1351510251
[90] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1351514408
[91] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1351522645
[92] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352300523
[93] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352304867
[94] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352814508
[95] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352821430
[96] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352825146
[97] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352890719
[98] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352891813
[99] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352892830
[100] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352900037
[101] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352900857
[102] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352904712
[103] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352906154
[104] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352979425
[105] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352979444
[106] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352982196
[107] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352984767
[108] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352984901
[109] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352988967
[110] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1352993592
[111] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353068868
[112] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353074609
[113] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353079327
[114] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353082475
[115] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353322097
[116] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353324133
[117] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353324183
[118] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353324254
[119] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353324289
[120] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353340264
[121] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353340576
[122] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353417970
[123] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353420496
[124] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353436758
[125] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353508577
[126] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353508871
[127] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353509250
[128] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353510434
[129] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1353510913
[130] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353516146
[131] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353516445
[132] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353588018
[133] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353588492
[134] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353589518
[135] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353590075
[136] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353591040
[137] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353591714
[138] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353591728
[139] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353592730
[140] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353593818
[141] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353594092
[142] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353594705
[143] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353596281
[144] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353596315
[145] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353599457
[146] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353599597
[147] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353602718
[148] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353602781
[149] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353931787
[150] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1353936396
[151] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354023957
[152] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354026929
[153] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354030627
[154] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354032553
[155] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354032884
[156] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354042154
[157] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354120966
[158] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354194215
[159] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354194281
[160] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354194316
[161] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354195452
[162] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354195501
[163] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354197217
[164] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354203311
[165] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354203338
[166] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354211574
[167] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1354211916
[168] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355156687
[169] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RAge_Resized images_1355158282
[170] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355250893
[171] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355264502
[172] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355273186
[173] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355279784
[174] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355309671
[175] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355314891
[176] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355322834
[177] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355326032
[178] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355333037
[179] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355337953
[180] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355349595
[181] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355356165
[182] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355357222
[183] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355361335
[184] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355395678
[185] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355399070
[186] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355402464
[187] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355409779
[188] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355410150
[189] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355440845
[190] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355449854
[191] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355454131
[192] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355484673
[193] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355484744
[194] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355491323
[195] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355494140
[196] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkLinear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355504058
[197] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355508515
[198] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355517571
[199] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355522098
[200] /local/tmp/escalafl/Alberto/SavedNetworks/NetworkNon-Linear Ultra Thin 11 Layer Network_ParNameFunction Based Data Creation for RTransXYScale_Resized images_1355536134
Network selected from program parameters:  -1
Selected: Train new network
Generating Network...
<SystemParameters.ParamsSFALayer object at 0x221e8d0>
<SystemParameters.ParamsSFALayer object at 0x221e910>
<SystemParameters.ParamsSFALayer object at 0x221e950>
<SystemParameters.ParamsSFALayer object at 0x221e990>
<SystemParameters.ParamsSFALayer object at 0x221e9d0>
<SystemParameters.ParamsSFALayer object at 0x221ea10>
<SystemParameters.ParamsSFALayer object at 0x221ea50>
<SystemParameters.ParamsSFALayer object at 0x221ea90>
<SystemParameters.ParamsSFALayer object at 0x221ead0>
<SystemParameters.ParamsSFALayer object at 0x221eb10>
<SystemParameters.ParamsSFALayer object at 0x221eb50>
SL= 0
sfa_expo and pca_expo across the network:
sSeq is: [[<SystemParameters.ParamsDataLoading object at 0x47a6b10>]]
sSeq is: <SystemParameters.ParamsDataLoading object at 0x47a6b10>
BB0
BB1
sSeq (list): [[<SystemParameters.ParamsDataLoading object at 0x47a6b10>]]
now building network
calling take_first_02D
calling take_first_02D again
Loading  60000 Images: width=256, height=192  subimage_width=128,subimage_height=128
color_background_filter is: None
60000 Training Images loaded in 204.436 s
******************************************
Creating hierarchy through network_builder
******************************************
Using Hierarchical Network:  Non-Linear Ultra Thin 11 Layer Network
Layers:  [<SystemParameters.ParamsSFALayer object at 0x22be450>, <SystemParameters.ParamsSFALayer object at 0x8189110>, <SystemParameters.ParamsSFALayer object at 0x8189150>, <SystemParameters.ParamsSFALayer object at 0x81891d0>, <SystemParameters.ParamsSFALayer object at 0x8189250>, <SystemParameters.ParamsSFALayer object at 0x81892d0>, <SystemParameters.ParamsSFALayer object at 0x81894d0>, <SystemParameters.ParamsSFALayer object at 0x8189550>, <SystemParameters.ParamsSFALayer object at 0x8189690>, <SystemParameters.ParamsSFALayer object at 0x81896d0>, <SystemParameters.ParamsSFALayer object at 0x8189710>]
layer  <SystemParameters.ParamsSFALayer object at 0x22be450>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x8189110>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x8189150>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x81891d0>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x8189250>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x81892d0>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x81894d0>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x8189550>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x8189690>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x81896d0>
here use pca_class to determine if block_size or train_mode is needed!!!
layer  <SystemParameters.ParamsSFALayer object at 0x8189710>
here use pca_class to determine if block_size or train_mode is needed!!!
*********************    Creating Layer *************************
Creating ParamsSFALayer L0
About to create (lattice based) intermediate layer widht=4, height=4
With a spacing of horiz=4, vert=4, and 1 channels
LA.x_in_channels, LA.y_in_channels =  128 128
[    0     1     2 ..., 16381 16382 16383]
Inverse connections already given, in PInvSwitchboard
Layer L0 with  1024  independent PCA nodes will be created
Layer L0 with  1024  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L1
About to create (lattice based) intermediate layer widht=2, height=1
With a spacing of horiz=2, vert=1, and 13 channels
LA.x_in_channels, LA.y_in_channels =  32 32
[    0     1     2 ..., 13309 13310 13311]
Inverse connections already given, in PInvSwitchboard
Layer L1 with  512  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L2
About to create (lattice based) intermediate layer widht=1, height=2
With a spacing of horiz=1, vert=2, and 20 channels
LA.x_in_channels, LA.y_in_channels =  16 32
[    0     1     2 ..., 10237 10238 10239]
Inverse connections already given, in PInvSwitchboard
Layer L2 with  256  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L3
About to create (lattice based) intermediate layer widht=2, height=1
With a spacing of horiz=2, vert=1, and 35 channels
LA.x_in_channels, LA.y_in_channels =  16 16
[   0    1    2 ..., 8957 8958 8959]
Inverse connections already given, in PInvSwitchboard
Layer L3 with  128  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L4
About to create (lattice based) intermediate layer widht=1, height=2
With a spacing of horiz=1, vert=2, and 60 channels
LA.x_in_channels, LA.y_in_channels =  8 16
[   0    1    2 ..., 7677 7678 7679]
Inverse connections already given, in PInvSwitchboard
Layer L4 with  64  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L5
About to create (lattice based) intermediate layer widht=2, height=1
With a spacing of horiz=2, vert=1, and 60 channels
LA.x_in_channels, LA.y_in_channels =  8 8
[   0    1    2 ..., 3837 3838 3839]
Inverse connections already given, in PInvSwitchboard
Layer L5 with  32  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L6
About to create (lattice based) intermediate layer widht=1, height=2
With a spacing of horiz=1, vert=2, and 60 channels
LA.x_in_channels, LA.y_in_channels =  4 8
[   0    1    2 ..., 1917 1918 1919]
Inverse connections already given, in PInvSwitchboard
Layer L6 with  16  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L7
About to create (lattice based) intermediate layer widht=2, height=1
With a spacing of horiz=2, vert=1, and 60 channels
LA.x_in_channels, LA.y_in_channels =  4 4
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899
 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917
 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935
 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953
 954 955 956 957 958 959]
Inverse connections already given, in PInvSwitchboard
Layer L7 with  8  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L8
About to create (lattice based) intermediate layer widht=1, height=2
With a spacing of horiz=1, vert=2, and 60 channels
LA.x_in_channels, LA.y_in_channels =  2 4
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59 120 121 122 123 124 125 126 127 128 129 130 131
 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167
 168 169 170 171 172 173 174 175 176 177 178 179  60  61  62  63  64  65
  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83
  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101
 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 360 361 362 363 364 365
 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383
 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401
 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419
 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317
 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335
 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353
 354 355 356 357 358 359 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479]
Inverse connections already given, in PInvSwitchboard
Layer L8 with  4  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L9
About to create (lattice based) intermediate layer widht=2, height=1
With a spacing of horiz=2, vert=1, and 60 channels
LA.x_in_channels, LA.y_in_channels =  2 2
Warning, mat_width <= 1 !!!
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239]
Inverse connections already given, in PInvSwitchboard
Layer L9 with  2  independent SFA nodes will be created
*********************    Creating Layer *************************
Creating ParamsSFALayer L10
About to create (lattice based) intermediate layer widht=1, height=2
With a spacing of horiz=1, vert=2, and 60 channels
LA.x_in_channels, LA.y_in_channels =  1 2
Warning, mat_width <= 1 !!!
[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119]
Inverse connections already given, in PInvSwitchboard
Layer L10 with  1  independent SFA nodes will be created
[<SystemParameters.ParamsSFALayer object at 0x22be450>, <SystemParameters.ParamsSFALayer object at 0x8189110>, <SystemParameters.ParamsSFALayer object at 0x8189150>, <SystemParameters.ParamsSFALayer object at 0x81891d0>, <SystemParameters.ParamsSFALayer object at 0x8189250>, <SystemParameters.ParamsSFALayer object at 0x81892d0>, <SystemParameters.ParamsSFALayer object at 0x81894d0>, <SystemParameters.ParamsSFALayer object at 0x8189550>, <SystemParameters.ParamsSFALayer object at 0x8189690>, <SystemParameters.ParamsSFALayer object at 0x81896d0>, <SystemParameters.ParamsSFALayer object at 0x8189710>]
L= <SystemParameters.ParamsSFALayer object at 0x22be450>
L.node_list= [PInvSwitchboard(input_dim=16384, output_dim=16384, dtype=None), Layer(input_dim=None, output_dim=13312, dtype=None), None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=13312, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x8189110>
L.node_list= [PInvSwitchboard(input_dim=13312, output_dim=13312, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=10240, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x8189150>
L.node_list= [PInvSwitchboard(input_dim=10240, output_dim=10240, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=8960, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x81891d0>
L.node_list= [PInvSwitchboard(input_dim=8960, output_dim=8960, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=7680, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x8189250>
L.node_list= [PInvSwitchboard(input_dim=7680, output_dim=7680, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=3840, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x81892d0>
L.node_list= [PInvSwitchboard(input_dim=3840, output_dim=3840, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=1920, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x81894d0>
L.node_list= [PInvSwitchboard(input_dim=1920, output_dim=1920, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=960, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x8189550>
L.node_list= [PInvSwitchboard(input_dim=960, output_dim=960, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=480, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x8189690>
L.node_list= [PInvSwitchboard(input_dim=480, output_dim=480, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=240, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x81896d0>
L.node_list= [PInvSwitchboard(input_dim=240, output_dim=240, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=120, dtype=None)]
L= <SystemParameters.ParamsSFALayer object at 0x8189710>
L.node_list= [PInvSwitchboard(input_dim=120, output_dim=120, dtype=None), None, None, CloneLayer(input_dim=None, output_dim=None, dtype=None), None, None, Layer(input_dim=None, output_dim=60, dtype=None)]
Flow.node_list= [PInvSwitchboard(input_dim=16384, output_dim=16384, dtype=None), Layer(input_dim=None, output_dim=13312, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=13312, dtype=None), PInvSwitchboard(input_dim=13312, output_dim=13312, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=10240, dtype=None), PInvSwitchboard(input_dim=10240, output_dim=10240, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=8960, dtype=None), PInvSwitchboard(input_dim=8960, output_dim=8960, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=7680, dtype=None), PInvSwitchboard(input_dim=7680, output_dim=7680, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=3840, dtype=None), PInvSwitchboard(input_dim=3840, output_dim=3840, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=1920, dtype=None), PInvSwitchboard(input_dim=1920, output_dim=1920, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=960, dtype=None), PInvSwitchboard(input_dim=960, output_dim=960, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=480, dtype=None), PInvSwitchboard(input_dim=480, output_dim=480, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=240, dtype=None), PInvSwitchboard(input_dim=240, output_dim=240, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=120, dtype=None), PInvSwitchboard(input_dim=120, output_dim=120, dtype=None), CloneLayer(input_dim=None, output_dim=None, dtype=None), Layer(input_dim=None, output_dim=60, dtype=None)]
Finished hierarchy construction, with total time 306.390 ms
(128, 128)
flow= [PInvSwitchboard, Layer, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer, PInvSwitchboard, CloneLayer, Layer]
34
Node:  PInvSwitchboard out_dim= 16384 input_dim 16384
Node:  Layer out_dim= 13312 input_dim None
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 13312 input_dim None
Node:  PInvSwitchboard out_dim= 13312 input_dim 13312
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 10240 input_dim None
Node:  PInvSwitchboard out_dim= 10240 input_dim 10240
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 8960 input_dim None
Node:  PInvSwitchboard out_dim= 8960 input_dim 8960
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 7680 input_dim None
Node:  PInvSwitchboard out_dim= 7680 input_dim 7680
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 3840 input_dim None
Node:  PInvSwitchboard out_dim= 3840 input_dim 3840
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 1920 input_dim None
Node:  PInvSwitchboard out_dim= 1920 input_dim 1920
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 960 input_dim None
Node:  PInvSwitchboard out_dim= 960 input_dim 960
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 480 input_dim None
Node:  PInvSwitchboard out_dim= 480 input_dim 480
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 240 input_dim None
Node:  PInvSwitchboard out_dim= 240 input_dim 240
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 120 input_dim None
Node:  PInvSwitchboard out_dim= 120 input_dim 120
Node:  CloneLayer out_dim= None input_dim None
Node:  Layer out_dim= 60 input_dim None
*****************************
Training hierarchy ...
*****************************
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
node_funcs is: [<function <lambda> at 0x22cdf50>]
Loading  60000 Images: width=256, height=192  subimage_width=128,subimage_height=128
color_background_filter is: None
node_data is: [array([[ 105.02673047,   91.95327536,   92.99873156, ...,   89.01609412,
          83.09998239,   74.99471886],
       [  75.99162002,   76.05900901,   75.99210374, ...,   27.02767641,
          32.10447372,   25.01771554],
       [  54.07009424,   55.01469833,   55.97081667, ...,   62.04161098,
          61.98975293,   61.94242293],
       ..., 
       [  24.00590834,   25.00537102,   24.031502  , ...,   57.96464796,
         110.9652312 ,  138.97664172],
       [ 207.03546808,  217.00496044,  218.93891336, ...,  117.97720415,
         133.02881415,  134.04337387],
       [ 179.00411632,  179.06531008,  173.97351265, ...,  101.06055497,
         100.0804427 ,  101.01093351]])]
*****************************************************************
Training node #0 (PInvSwitchboard)... untrained_node_hash[0]= bb8348a5daf2d4c9cc39408221aff24e
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[0]= 82b9bae99a81f4cf5a9bbe74b8aa4216
trained_node_hash[0]= bb8348a5daf2d4c9cc39408221aff24e
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 105.02673047,   91.95327536,   92.99873156, ...,   89.01609412,
          83.09998239,   74.99471886],
       [  75.99162002,   76.05900901,   75.99210374, ...,   27.02767641,
          32.10447372,   25.01771554],
       [  54.07009424,   55.01469833,   55.97081667, ...,   62.04161098,
          61.98975293,   61.94242293],
       ..., 
       [  24.00590834,   25.00537102,   24.031502  , ...,   57.96464796,
         110.9652312 ,  138.97664172],
       [ 207.03546808,  217.00496044,  218.93891336, ...,  117.97720415,
         133.02881415,  134.04337387],
       [ 179.00411632,  179.06531008,  173.97351265, ...,  101.06055497,
         100.0804427 ,  101.01093351]])]
Post3 self.flow[i].output_dim= 16384
data_vec [array([[ 105.02673047,   91.95327536,   92.99873156, ...,   89.01609412,
          83.09998239,   74.99471886],
       [  75.99162002,   76.05900901,   75.99210374, ...,   27.02767641,
          32.10447372,   25.01771554],
       [  54.07009424,   55.01469833,   55.97081667, ...,   62.04161098,
          61.98975293,   61.94242293],
       ..., 
       [  24.00590834,   25.00537102,   24.031502  , ...,   57.96464796,
         110.9652312 ,  138.97664172],
       [ 207.03546808,  217.00496044,  218.93891336, ...,  117.97720415,
         133.02881415,  134.04337387],
       [ 179.00411632,  179.06531008,  173.97351265, ...,  101.06055497,
         100.0804427 ,  101.01093351]])]
len(data_vec) 1
data_vec[0].shape (60000, 16384)
Training finished in 3.258 s, execution in 51.340 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #1 (Layer)... of [PCANode]
untrained_node_hash[1]= b9e8c0593392bc9e6b62aad8aaf4dd6c
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[1]= 82b9bae99a81f4cf5a9bbe74b8aa4216
Searching for Trained Node: node_16384_b9e8c0593392bc9e6b62aad8aaf4dd6c_82b9bae99a81f4cf5a9bbe74b8aa4216
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_16384_b9e8c0593392bc9e6b62aad8aaf4dd6c_82b9bae99a81f4cf5a9bbe74b8aa4216.pckl
Trained node FOUND in cache...
trained_node_hash[1]= 1cc0816d0d85c285d7ecd277ee092977
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 105.02673047,   91.95327536,   92.99873156, ...,   89.01609412,
          83.09998239,   74.99471886],
       [  75.99162002,   76.05900901,   75.99210374, ...,   27.02767641,
          32.10447372,   25.01771554],
       [  54.07009424,   55.01469833,   55.97081667, ...,   62.04161098,
          61.98975293,   61.94242293],
       ..., 
       [  24.00590834,   25.00537102,   24.031502  , ...,   57.96464796,
         110.9652312 ,  138.97664172],
       [ 207.03546808,  217.00496044,  218.93891336, ...,  117.97720415,
         133.02881415,  134.04337387],
       [ 179.00411632,  179.06531008,  173.97351265, ...,  101.06055497,
         100.0804427 ,  101.01093351]])]
Post3 self.flow[i].output_dim= 13312
data_vec [array([[  5.78469586e+01,   1.18579935e+01,   1.55487870e+01, ...,
         -1.20010094e+01,   3.97207677e+00,  -2.64966877e+00],
       [  1.11009550e+02,   2.29570075e+00,   2.73403849e+00, ...,
          3.88087911e+00,   4.35190766e-01,  -1.69193764e+00],
       [  1.85954252e+02,  -3.05142191e+00,   3.68051211e-01, ...,
         -3.37361249e-01,  -1.19691877e+00,  -6.96665935e-01],
       ..., 
       [  2.83517783e+02,  -6.81650310e+00,  -2.36861604e+01, ...,
         -4.32119454e+00,  -4.14007229e+00,  -2.74277607e+00],
       [ -4.27985879e+02,  -1.56311870e+00,   1.29659313e+01, ...,
          3.11907574e+00,  -5.43853759e+00,  -3.38178147e+00],
       [ -2.83542401e+02,   6.92500908e+00,   1.37035116e+01, ...,
          4.28018651e-01,  -1.34995805e-01,   3.99084734e-01]])]
len(data_vec) 1
data_vec[0].shape (60000, 13312)
Training finished in 38.669 s, execution in 51.238 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #2 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[2]= ada34b45cf7d01067f827ee9290fff6b
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[2]= 0da11d7a057675dea7f70fd211203b7b
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[2]= ada34b45cf7d01067f827ee9290fff6b
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[  5.78469586e+01,   1.18579935e+01,   1.55487870e+01, ...,
         -1.20010094e+01,   3.97207677e+00,  -2.64966877e+00],
       [  1.11009550e+02,   2.29570075e+00,   2.73403849e+00, ...,
          3.88087911e+00,   4.35190766e-01,  -1.69193764e+00],
       [  1.85954252e+02,  -3.05142191e+00,   3.68051211e-01, ...,
         -3.37361249e-01,  -1.19691877e+00,  -6.96665935e-01],
       ..., 
       [  2.83517783e+02,  -6.81650310e+00,  -2.36861604e+01, ...,
         -4.32119454e+00,  -4.14007229e+00,  -2.74277607e+00],
       [ -4.27985879e+02,  -1.56311870e+00,   1.29659313e+01, ...,
          3.11907574e+00,  -5.43853759e+00,  -3.38178147e+00],
       [ -2.83542401e+02,   6.92500908e+00,   1.37035116e+01, ...,
          4.28018651e-01,  -1.34995805e-01,   3.99084734e-01]])]
Pre_Execution of homogeneous layer with input_dim 13312 and 1024 nodes
Post3 self.flow[i].output_dim= 26624
data_vec [array([[  5.78469586e+01,   1.18579935e+01,   1.55487870e+01, ...,
          7.30086336e+00,   3.01449180e+00,   2.18048583e+00],
       [  1.11009550e+02,   2.29570075e+00,   2.73403849e+00, ...,
          2.95899405e+00,   5.13977062e-01,   1.52302657e+00],
       [  1.85954252e+02,  -3.05142191e+00,   3.68051211e-01, ...,
          4.19252978e-01,   1.15465367e+00,   7.48892809e-01],
       ..., 
       [  2.83517783e+02,  -6.81650310e+00,  -2.36861604e+01, ...,
          3.22465350e+00,   3.11606379e+00,   2.24156987e+00],
       [ -4.27985879e+02,  -1.56311870e+00,   1.29659313e+01, ...,
          2.48439552e+00,   3.87601731e+00,   2.65043057e+00],
       [ -2.83542401e+02,   6.92500908e+00,   1.37035116e+01, ...,
          5.07189384e-01,   2.01491262e-01,   4.79570094e-01]])]
len(data_vec) 1
data_vec[0].shape (60000, 26624)
Training finished in 4.271 s, execution in 196.539 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #3 (Layer)... of [SFANode]
untrained_node_hash[3]= 52b23654957e96580df15d8498064afe
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[3]= 17cccf42aaac92eedda9236268ad48ef
Searching for Trained Node: node_26624_52b23654957e96580df15d8498064afe_17cccf42aaac92eedda9236268ad48ef
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_26624_52b23654957e96580df15d8498064afe_17cccf42aaac92eedda9236268ad48ef.pckl
Trained node FOUND in cache...
trained_node_hash[3]= dee97914b6ead0a784f19fa5b2f86bd6
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[  5.78469586e+01,   1.18579935e+01,   1.55487870e+01, ...,
          7.30086336e+00,   3.01449180e+00,   2.18048583e+00],
       [  1.11009550e+02,   2.29570075e+00,   2.73403849e+00, ...,
          2.95899405e+00,   5.13977062e-01,   1.52302657e+00],
       [  1.85954252e+02,  -3.05142191e+00,   3.68051211e-01, ...,
          4.19252978e-01,   1.15465367e+00,   7.48892809e-01],
       ..., 
       [  2.83517783e+02,  -6.81650310e+00,  -2.36861604e+01, ...,
          3.22465350e+00,   3.11606379e+00,   2.24156987e+00],
       [ -4.27985879e+02,  -1.56311870e+00,   1.29659313e+01, ...,
          2.48439552e+00,   3.87601731e+00,   2.65043057e+00],
       [ -2.83542401e+02,   6.92500908e+00,   1.37035116e+01, ...,
          5.07189384e-01,   2.01491262e-01,   4.79570094e-01]])]
Post3 self.flow[i].output_dim= 13312
data_vec [array([[ 0.74166343,  0.07708657,  0.6389702 , ...,  0.6423478 ,
        -0.40128319, -0.59050485],
       [ 0.37332616,  0.44068624, -0.39672719, ..., -0.63266703,
        -0.07775125, -0.97489587],
       [-0.02175217,  0.68925032, -0.37428611, ...,  0.09462224,
         0.41714588, -0.05135436],
       ..., 
       [-0.83702401, -0.06232517, -0.88273629, ...,  0.07282722,
         0.03283396, -0.28045734],
       [-0.40951531, -2.00113029, -0.07023549, ..., -0.58384285,
        -0.15874135, -0.83599607],
       [-0.21681107, -1.09320479, -0.39177992, ..., -0.05190692,
         0.63606522, -0.75296239]])]
len(data_vec) 1
data_vec[0].shape (60000, 13312)
Training finished in 6.127 s, execution in 79.385 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #4 (PInvSwitchboard)... untrained_node_hash[4]= 517ab8a90ee5d2a7b426689fa6dda455
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[4]= 8fe27d0fcfda9344da9ca1804efa9e31
trained_node_hash[4]= 517ab8a90ee5d2a7b426689fa6dda455
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.74166343,  0.07708657,  0.6389702 , ...,  0.6423478 ,
        -0.40128319, -0.59050485],
       [ 0.37332616,  0.44068624, -0.39672719, ..., -0.63266703,
        -0.07775125, -0.97489587],
       [-0.02175217,  0.68925032, -0.37428611, ...,  0.09462224,
         0.41714588, -0.05135436],
       ..., 
       [-0.83702401, -0.06232517, -0.88273629, ...,  0.07282722,
         0.03283396, -0.28045734],
       [-0.40951531, -2.00113029, -0.07023549, ..., -0.58384285,
        -0.15874135, -0.83599607],
       [-0.21681107, -1.09320479, -0.39177992, ..., -0.05190692,
         0.63606522, -0.75296239]])]
Post3 self.flow[i].output_dim= 13312
data_vec [array([[ 0.74166343,  0.07708657,  0.6389702 , ...,  0.6423478 ,
        -0.40128319, -0.59050485],
       [ 0.37332616,  0.44068624, -0.39672719, ..., -0.63266703,
        -0.07775125, -0.97489587],
       [-0.02175217,  0.68925032, -0.37428611, ...,  0.09462224,
         0.41714588, -0.05135436],
       ..., 
       [-0.83702401, -0.06232517, -0.88273629, ...,  0.07282722,
         0.03283396, -0.28045734],
       [-0.40951531, -2.00113029, -0.07023549, ..., -0.58384285,
        -0.15874135, -0.83599607],
       [-0.21681107, -1.09320479, -0.39177992, ..., -0.05190692,
         0.63606522, -0.75296239]])]
len(data_vec) 1
data_vec[0].shape (60000, 13312)
Training finished in 3.045 s, execution in 35.968 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #5 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[5]= df6d807979297770ab8b7fd515d223af
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[5]= 8fe27d0fcfda9344da9ca1804efa9e31
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[5]= df6d807979297770ab8b7fd515d223af
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.74166343,  0.07708657,  0.6389702 , ...,  0.6423478 ,
        -0.40128319, -0.59050485],
       [ 0.37332616,  0.44068624, -0.39672719, ..., -0.63266703,
        -0.07775125, -0.97489587],
       [-0.02175217,  0.68925032, -0.37428611, ...,  0.09462224,
         0.41714588, -0.05135436],
       ..., 
       [-0.83702401, -0.06232517, -0.88273629, ...,  0.07282722,
         0.03283396, -0.28045734],
       [-0.40951531, -2.00113029, -0.07023549, ..., -0.58384285,
        -0.15874135, -0.83599607],
       [-0.21681107, -1.09320479, -0.39177992, ..., -0.05190692,
         0.63606522, -0.75296239]])]
Pre_Execution of homogeneous layer with input_dim 13312 and 512 nodes
Post3 self.flow[i].output_dim= 26624
data_vec [array([[ 0.74166343,  0.07708657,  0.6389702 , ...,  0.70180457,
         0.48168239,  0.6561132 ],
       [ 0.37332616,  0.44068624, -0.39672719, ...,  0.69333027,
         0.12958833,  0.97986576],
       [-0.02175217,  0.68925032, -0.37428611, ...,  0.15163329,
         0.4968558 ,  0.09299548],
       ..., 
       [-0.83702401, -0.06232517, -0.88273629, ...,  0.12298014,
         0.06502174,  0.36165415],
       [-0.40951531, -2.00113029, -0.07023549, ...,  0.65018474,
         0.22937815,  0.86648967],
       [-0.21681107, -1.09320479, -0.39177992, ...,  0.09379511,
         0.69630789,  0.79692716]])]
len(data_vec) 1
data_vec[0].shape (60000, 26624)
Training finished in 30.845 s, execution in 152.406 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #6 (Layer)... of [SFANode]
untrained_node_hash[6]= 24be0c248621070d4ce8f3f085578a28
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[6]= e0ae5e5cd9cda9bf87469fcc4d8209fb
Searching for Trained Node: node_26624_24be0c248621070d4ce8f3f085578a28_e0ae5e5cd9cda9bf87469fcc4d8209fb
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_26624_24be0c248621070d4ce8f3f085578a28_e0ae5e5cd9cda9bf87469fcc4d8209fb.pckl
Trained node FOUND in cache...
trained_node_hash[6]= a976b261966778aa8e90a99e29e6b821
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.74166343,  0.07708657,  0.6389702 , ...,  0.70180457,
         0.48168239,  0.6561132 ],
       [ 0.37332616,  0.44068624, -0.39672719, ...,  0.69333027,
         0.12958833,  0.97986576],
       [-0.02175217,  0.68925032, -0.37428611, ...,  0.15163329,
         0.4968558 ,  0.09299548],
       ..., 
       [-0.83702401, -0.06232517, -0.88273629, ...,  0.12298014,
         0.06502174,  0.36165415],
       [-0.40951531, -2.00113029, -0.07023549, ...,  0.65018474,
         0.22937815,  0.86648967],
       [-0.21681107, -1.09320479, -0.39177992, ...,  0.09379511,
         0.69630789,  0.79692716]])]
Post3 self.flow[i].output_dim= 10240
data_vec [array([[-0.36899011,  0.62206942,  0.569909  , ...,  0.39512835,
        -0.50738065,  0.07985972],
       [-0.93539236, -0.12587087, -0.41559708, ...,  0.41557778,
        -0.05290232, -0.34912369],
       [-0.25673547, -0.39335715, -0.517575  , ..., -0.03923079,
        -0.38652489,  0.73938883],
       ..., 
       [-0.72358866,  0.21078163, -1.42535057, ..., -0.33264158,
         1.78474409, -1.50785876],
       [ 1.3937587 ,  1.43837461, -0.47314707, ...,  0.59242786,
         0.10074921, -0.28178842],
       [ 0.85745974,  1.0989879 , -0.15282419, ..., -0.36216296,
         0.07901453,  0.52184906]])]
len(data_vec) 1
data_vec[0].shape (60000, 10240)
Training finished in 6.633 s, execution in 70.666 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #7 (PInvSwitchboard)... untrained_node_hash[7]= 88217d720a50f5e0246197923f85e38d
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[7]= a6c44a9523133d2911f84694b153cd30
trained_node_hash[7]= 88217d720a50f5e0246197923f85e38d
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.36899011,  0.62206942,  0.569909  , ...,  0.39512835,
        -0.50738065,  0.07985972],
       [-0.93539236, -0.12587087, -0.41559708, ...,  0.41557778,
        -0.05290232, -0.34912369],
       [-0.25673547, -0.39335715, -0.517575  , ..., -0.03923079,
        -0.38652489,  0.73938883],
       ..., 
       [-0.72358866,  0.21078163, -1.42535057, ..., -0.33264158,
         1.78474409, -1.50785876],
       [ 1.3937587 ,  1.43837461, -0.47314707, ...,  0.59242786,
         0.10074921, -0.28178842],
       [ 0.85745974,  1.0989879 , -0.15282419, ..., -0.36216296,
         0.07901453,  0.52184906]])]
Post3 self.flow[i].output_dim= 10240
data_vec [array([[-0.36899011,  0.62206942,  0.569909  , ...,  0.39512835,
        -0.50738065,  0.07985972],
       [-0.93539236, -0.12587087, -0.41559708, ...,  0.41557778,
        -0.05290232, -0.34912369],
       [-0.25673547, -0.39335715, -0.517575  , ..., -0.03923079,
        -0.38652489,  0.73938883],
       ..., 
       [-0.72358866,  0.21078163, -1.42535057, ..., -0.33264158,
         1.78474409, -1.50785876],
       [ 1.3937587 ,  1.43837461, -0.47314707, ...,  0.59242786,
         0.10074921, -0.28178842],
       [ 0.85745974,  1.0989879 , -0.15282419, ..., -0.36216296,
         0.07901453,  0.52184906]])]
len(data_vec) 1
data_vec[0].shape (60000, 10240)
Training finished in 2.514 s, execution in 26.570 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #8 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[8]= ea68f07bf4f77c4259df5a1c89505952
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[8]= f924f5832a2077856951d373a170a05c
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[8]= ea68f07bf4f77c4259df5a1c89505952
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.36899011,  0.62206942,  0.569909  , ...,  0.39512835,
        -0.50738065,  0.07985972],
       [-0.93539236, -0.12587087, -0.41559708, ...,  0.41557778,
        -0.05290232, -0.34912369],
       [-0.25673547, -0.39335715, -0.517575  , ..., -0.03923079,
        -0.38652489,  0.73938883],
       ..., 
       [-0.72358866,  0.21078163, -1.42535057, ..., -0.33264158,
         1.78474409, -1.50785876],
       [ 1.3937587 ,  1.43837461, -0.47314707, ...,  0.59242786,
         0.10074921, -0.28178842],
       [ 0.85745974,  1.0989879 , -0.15282419, ..., -0.36216296,
         0.07901453,  0.52184906]])]
Pre_Execution of homogeneous layer with input_dim 10240 and 256 nodes
Post3 self.flow[i].output_dim= 20480
data_vec [array([[-0.36899011,  0.62206942,  0.569909  , ...,  0.47576287,
         0.58112173,  0.13239215],
       [-0.93539236, -0.12587087, -0.41559708, ...,  0.49536105,
         0.09523131,  0.4309069 ],
       [-0.25673547, -0.39335715, -0.517575  , ...,  0.07497244,
         0.46745732,  0.7854134 ],
       ..., 
       [-0.72358866,  0.21078163, -1.42535057, ...,  0.41455412,
         1.58950084,  1.38895614],
       [ 1.3937587 ,  1.43837461, -0.47314707, ...,  0.65782198,
         0.15943855,  0.36302666],
       [ 0.85745974,  1.0989879 , -0.15282419, ...,  0.44373453,
         0.13127003,  0.59434132]])]
len(data_vec) 1
data_vec[0].shape (60000, 20480)
Training finished in 23.512 s, execution in 105.552 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #9 (Layer)... of [SFANode]
untrained_node_hash[9]= ad5c3fefc198ec3026392a8cd005482f
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[9]= 1b4a330af2032d125ae4467b3ba09ad3
Searching for Trained Node: node_20480_ad5c3fefc198ec3026392a8cd005482f_1b4a330af2032d125ae4467b3ba09ad3
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_20480_ad5c3fefc198ec3026392a8cd005482f_1b4a330af2032d125ae4467b3ba09ad3.pckl
Trained node FOUND in cache...
trained_node_hash[9]= 2bbfa028c26442bb2a0f41bbe362e949
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.36899011,  0.62206942,  0.569909  , ...,  0.47576287,
         0.58112173,  0.13239215],
       [-0.93539236, -0.12587087, -0.41559708, ...,  0.49536105,
         0.09523131,  0.4309069 ],
       [-0.25673547, -0.39335715, -0.517575  , ...,  0.07497244,
         0.46745732,  0.7854134 ],
       ..., 
       [-0.72358866,  0.21078163, -1.42535057, ...,  0.41455412,
         1.58950084,  1.38895614],
       [ 1.3937587 ,  1.43837461, -0.47314707, ...,  0.65782198,
         0.15943855,  0.36302666],
       [ 0.85745974,  1.0989879 , -0.15282419, ...,  0.44373453,
         0.13127003,  0.59434132]])]
Post3 self.flow[i].output_dim= 8960
data_vec [array([[-0.15160073, -0.00509131, -0.51352822, ...,  0.71817945,
        -0.1846559 ,  0.17985408],
       [-1.20031127, -0.19616381,  0.27184125, ...,  0.38887659,
        -0.24572584, -0.31826375],
       [-0.74137199,  0.24477774,  0.53536158, ..., -0.93295174,
        -0.28931384, -0.28755101],
       ..., 
       [-0.46878147, -2.06662333,  2.01856675, ..., -0.14476828,
         0.18190565, -0.10407188],
       [ 1.20670056, -1.57584595,  0.48810856, ..., -0.25459906,
        -0.27788522, -0.32361469],
       [ 0.70995595, -1.08494965,  0.4866514 , ..., -0.13215451,
        -0.12543352,  0.00629735]])]
len(data_vec) 1
data_vec[0].shape (60000, 8960)
Training finished in 4.497 s, execution in 56.029 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #10 (PInvSwitchboard)... untrained_node_hash[10]= 07e46796258e53b6942a30708a5a9c6e
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[10]= b6fd29ea9bed1373813cf9bd84bee406
trained_node_hash[10]= 07e46796258e53b6942a30708a5a9c6e
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.15160073, -0.00509131, -0.51352822, ...,  0.71817945,
        -0.1846559 ,  0.17985408],
       [-1.20031127, -0.19616381,  0.27184125, ...,  0.38887659,
        -0.24572584, -0.31826375],
       [-0.74137199,  0.24477774,  0.53536158, ..., -0.93295174,
        -0.28931384, -0.28755101],
       ..., 
       [-0.46878147, -2.06662333,  2.01856675, ..., -0.14476828,
         0.18190565, -0.10407188],
       [ 1.20670056, -1.57584595,  0.48810856, ..., -0.25459906,
        -0.27788522, -0.32361469],
       [ 0.70995595, -1.08494965,  0.4866514 , ..., -0.13215451,
        -0.12543352,  0.00629735]])]
Post3 self.flow[i].output_dim= 8960
data_vec [array([[-0.15160073, -0.00509131, -0.51352822, ...,  0.71817945,
        -0.1846559 ,  0.17985408],
       [-1.20031127, -0.19616381,  0.27184125, ...,  0.38887659,
        -0.24572584, -0.31826375],
       [-0.74137199,  0.24477774,  0.53536158, ..., -0.93295174,
        -0.28931384, -0.28755101],
       ..., 
       [-0.46878147, -2.06662333,  2.01856675, ..., -0.14476828,
         0.18190565, -0.10407188],
       [ 1.20670056, -1.57584595,  0.48810856, ..., -0.25459906,
        -0.27788522, -0.32361469],
       [ 0.70995595, -1.08494965,  0.4866514 , ..., -0.13215451,
        -0.12543352,  0.00629735]])]
len(data_vec) 1
data_vec[0].shape (60000, 8960)
Training finished in 1.878 s, execution in 20.902 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #11 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[11]= c28c541536f628afea7b0e67e5200bc4
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[11]= b6fd29ea9bed1373813cf9bd84bee406
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[11]= c28c541536f628afea7b0e67e5200bc4
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.15160073, -0.00509131, -0.51352822, ...,  0.71817945,
        -0.1846559 ,  0.17985408],
       [-1.20031127, -0.19616381,  0.27184125, ...,  0.38887659,
        -0.24572584, -0.31826375],
       [-0.74137199,  0.24477774,  0.53536158, ..., -0.93295174,
        -0.28931384, -0.28755101],
       ..., 
       [-0.46878147, -2.06662333,  2.01856675, ..., -0.14476828,
         0.18190565, -0.10407188],
       [ 1.20670056, -1.57584595,  0.48810856, ..., -0.25459906,
        -0.27788522, -0.32361469],
       [ 0.70995595, -1.08494965,  0.4866514 , ..., -0.13215451,
        -0.12543352,  0.00629735]])]
Pre_Execution of homogeneous layer with input_dim 8960 and 128 nodes
Post3 self.flow[i].output_dim= 17920
data_vec [array([[-0.15160073, -0.00509131, -0.51352822, ...,  0.76733742,
         0.25887526,  0.25347565],
       [-1.20031127, -0.19616381,  0.27184125, ...,  0.46973123,
         0.32535738,  0.40015638],
       [-0.74137199,  0.24477774,  0.53536158, ...,  0.94599174,
         0.37076213,  0.36895374],
       ..., 
       [-0.46878147, -2.06662333,  2.01856675, ...,  0.21307806,
         0.25578611,  0.16363143],
       [ 1.20670056, -1.57584595,  0.48810856, ...,  0.3347229 ,
         0.35899827,  0.40552963],
       [ 0.70995595, -1.08494965,  0.4866514 , ...,  0.19809138,
         0.18999006,  0.01735107]])]
len(data_vec) 1
data_vec[0].shape (60000, 17920)
Training finished in 20.831 s, execution in 97.540 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #12 (Layer)... of [SFANode]
untrained_node_hash[12]= 5c1d2c3d1f3256c9e92809f023eebeb2
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[12]= 769b43ffee527648365b8e3c0a8a8a5f
Searching for Trained Node: node_17920_5c1d2c3d1f3256c9e92809f023eebeb2_769b43ffee527648365b8e3c0a8a8a5f
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_17920_5c1d2c3d1f3256c9e92809f023eebeb2_769b43ffee527648365b8e3c0a8a8a5f.pckl
Trained node FOUND in cache...
trained_node_hash[12]= 5d31672695da4116da3a37b05fd086b3
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.15160073, -0.00509131, -0.51352822, ...,  0.76733742,
         0.25887526,  0.25347565],
       [-1.20031127, -0.19616381,  0.27184125, ...,  0.46973123,
         0.32535738,  0.40015638],
       [-0.74137199,  0.24477774,  0.53536158, ...,  0.94599174,
         0.37076213,  0.36895374],
       ..., 
       [-0.46878147, -2.06662333,  2.01856675, ...,  0.21307806,
         0.25578611,  0.16363143],
       [ 1.20670056, -1.57584595,  0.48810856, ...,  0.3347229 ,
         0.35899827,  0.40552963],
       [ 0.70995595, -1.08494965,  0.4866514 , ...,  0.19809138,
         0.18999006,  0.01735107]])]
Post3 self.flow[i].output_dim= 7680
data_vec [array([[  1.94027774e-01,   5.97506203e-01,   2.00910060e-01, ...,
          7.74593058e-01,  -8.29480743e-01,  -4.16482489e-01],
       [ -1.28635849e+00,   2.46584040e-01,   1.35347667e-01, ...,
         -1.80555360e+00,   2.36995610e+00,   1.94259369e-01],
       [ -9.68238051e-01,  -5.87618180e-04,  -2.36255064e-01, ...,
          7.25775041e-02,  -7.45657366e-03,   1.06563514e+00],
       ..., 
       [ -6.13433526e-01,   1.41124599e+00,  -1.41842571e+00, ...,
         -2.68956397e-01,   1.44861265e+00,  -5.77527614e-01],
       [  5.19612298e-01,   1.15025459e+00,  -1.13426017e+00, ...,
         -6.03451026e-01,  -1.21474974e+00,   6.35987034e-01],
       [  7.88349037e-01,   1.14812358e+00,  -6.06791347e-01, ...,
         -1.12355117e-01,  -5.13103402e-03,   3.73884513e-01]])]
len(data_vec) 1
data_vec[0].shape (60000, 7680)
Training finished in 3.866 s, execution in 68.088 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #13 (PInvSwitchboard)... untrained_node_hash[13]= a58b3591ffbf8d28eb770374fa93a130
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[13]= 9fafeaa0556e11198f01fa11f5a029f1
trained_node_hash[13]= a58b3591ffbf8d28eb770374fa93a130
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[  1.94027774e-01,   5.97506203e-01,   2.00910060e-01, ...,
          7.74593058e-01,  -8.29480743e-01,  -4.16482489e-01],
       [ -1.28635849e+00,   2.46584040e-01,   1.35347667e-01, ...,
         -1.80555360e+00,   2.36995610e+00,   1.94259369e-01],
       [ -9.68238051e-01,  -5.87618180e-04,  -2.36255064e-01, ...,
          7.25775041e-02,  -7.45657366e-03,   1.06563514e+00],
       ..., 
       [ -6.13433526e-01,   1.41124599e+00,  -1.41842571e+00, ...,
         -2.68956397e-01,   1.44861265e+00,  -5.77527614e-01],
       [  5.19612298e-01,   1.15025459e+00,  -1.13426017e+00, ...,
         -6.03451026e-01,  -1.21474974e+00,   6.35987034e-01],
       [  7.88349037e-01,   1.14812358e+00,  -6.06791347e-01, ...,
         -1.12355117e-01,  -5.13103402e-03,   3.73884513e-01]])]
Post3 self.flow[i].output_dim= 7680
data_vec [array([[  1.94027774e-01,   5.97506203e-01,   2.00910060e-01, ...,
          7.74593058e-01,  -8.29480743e-01,  -4.16482489e-01],
       [ -1.28635849e+00,   2.46584040e-01,   1.35347667e-01, ...,
         -1.80555360e+00,   2.36995610e+00,   1.94259369e-01],
       [ -9.68238051e-01,  -5.87618180e-04,  -2.36255064e-01, ...,
          7.25775041e-02,  -7.45657366e-03,   1.06563514e+00],
       ..., 
       [ -6.13433526e-01,   1.41124599e+00,  -1.41842571e+00, ...,
         -2.68956397e-01,   1.44861265e+00,  -5.77527614e-01],
       [  5.19612298e-01,   1.15025459e+00,  -1.13426017e+00, ...,
         -6.03451026e-01,  -1.21474974e+00,   6.35987034e-01],
       [  7.88349037e-01,   1.14812358e+00,  -6.06791347e-01, ...,
         -1.12355117e-01,  -5.13103402e-03,   3.73884513e-01]])]
len(data_vec) 1
data_vec[0].shape (60000, 7680)
Training finished in 2.089 s, execution in 20.560 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #14 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[14]= 42b46c8ed58dbb1b1b5b93d48f681204
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[14]= 949e8ed9011fbbabc68aff8a4d43fcb1
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[14]= 42b46c8ed58dbb1b1b5b93d48f681204
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[  1.94027774e-01,   5.97506203e-01,   2.00910060e-01, ...,
          7.74593058e-01,  -8.29480743e-01,  -4.16482489e-01],
       [ -1.28635849e+00,   2.46584040e-01,   1.35347667e-01, ...,
         -1.80555360e+00,   2.36995610e+00,   1.94259369e-01],
       [ -9.68238051e-01,  -5.87618180e-04,  -2.36255064e-01, ...,
          7.25775041e-02,  -7.45657366e-03,   1.06563514e+00],
       ..., 
       [ -6.13433526e-01,   1.41124599e+00,  -1.41842571e+00, ...,
         -2.68956397e-01,   1.44861265e+00,  -5.77527614e-01],
       [  5.19612298e-01,   1.15025459e+00,  -1.13426017e+00, ...,
         -6.03451026e-01,  -1.21474974e+00,   6.35987034e-01],
       [  7.88349037e-01,   1.14812358e+00,  -6.06791347e-01, ...,
         -1.12355117e-01,  -5.13103402e-03,   3.73884513e-01]])]
Pre_Execution of homogeneous layer with input_dim 7680 and 64 nodes
Post3 self.flow[i].output_dim= 15360
data_vec [array([[  1.94027774e-01,   5.97506203e-01,   2.00910060e-01, ...,
          8.15190069e-01,   8.61083062e-01,   4.96223580e-01],
       [ -1.28635849e+00,   2.46584040e-01,   1.35347667e-01, ...,
          1.60431007e+00,   1.99430805e+00,   2.69591118e-01],
       [ -9.68238051e-01,  -5.87618180e-04,  -2.36255064e-01, ...,
          1.22642677e-01,   1.98623875e-02,   1.05217221e+00],
       ..., 
       [ -6.13433526e-01,   1.41124599e+00,  -1.41842571e+00, ...,
          3.49740159e-01,   1.34512244e+00,   6.44552361e-01],
       [  5.19612298e-01,   1.15025459e+00,  -1.13426017e+00, ...,
          6.67595843e-01,   1.16839436e+00,   6.96239421e-01],
       [  7.88349037e-01,   1.14812358e+00,  -6.06791347e-01, ...,
          1.73969968e-01,   1.47286830e-02,   4.55187137e-01]])]
len(data_vec) 1
data_vec[0].shape (60000, 15360)
Training finished in 18.213 s, execution in 86.685 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #15 (Layer)... of [SFANode]
untrained_node_hash[15]= 7a102b1973f402e3c4a6c09f33b537c4
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[15]= af7e91087e129505e96dff7ac95e4480
Searching for Trained Node: node_15360_7a102b1973f402e3c4a6c09f33b537c4_af7e91087e129505e96dff7ac95e4480
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_15360_7a102b1973f402e3c4a6c09f33b537c4_af7e91087e129505e96dff7ac95e4480.pckl
Trained node FOUND in cache...
trained_node_hash[15]= 5a2873a41a5ab5f3e4184f425932cf07
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[  1.94027774e-01,   5.97506203e-01,   2.00910060e-01, ...,
          8.15190069e-01,   8.61083062e-01,   4.96223580e-01],
       [ -1.28635849e+00,   2.46584040e-01,   1.35347667e-01, ...,
          1.60431007e+00,   1.99430805e+00,   2.69591118e-01],
       [ -9.68238051e-01,  -5.87618180e-04,  -2.36255064e-01, ...,
          1.22642677e-01,   1.98623875e-02,   1.05217221e+00],
       ..., 
       [ -6.13433526e-01,   1.41124599e+00,  -1.41842571e+00, ...,
          3.49740159e-01,   1.34512244e+00,   6.44552361e-01],
       [  5.19612298e-01,   1.15025459e+00,  -1.13426017e+00, ...,
          6.67595843e-01,   1.16839436e+00,   6.96239421e-01],
       [  7.88349037e-01,   1.14812358e+00,  -6.06791347e-01, ...,
          1.73969968e-01,   1.47286830e-02,   4.55187137e-01]])]
Post3 self.flow[i].output_dim= 3840
data_vec [array([[ 0.06394133, -0.87328205,  0.94261452, ...,  0.39500421,
        -0.762914  ,  0.24152084],
       [-1.31429348, -0.43025474, -0.28676832, ..., -0.23666173,
        -1.32341632, -1.35708401],
       [-1.3113524 , -0.29860849, -0.47262697, ...,  1.39863306,
        -0.09161527,  0.14555416],
       ..., 
       [ 0.75518537, -2.12073533,  1.06159465, ..., -1.00083842,
         0.52193842,  0.9648458 ],
       [ 0.21978447, -1.72758442,  1.19367969, ...,  0.93497708,
         0.37058201, -0.39562104],
       [ 0.32544459, -0.98767095,  0.70516339, ...,  0.05936922,
         0.03592098, -0.19786472]])]
len(data_vec) 1
data_vec[0].shape (60000, 3840)
Training finished in 4.451 s, execution in 51.843 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #16 (PInvSwitchboard)... untrained_node_hash[16]= df45ed28a9b9afd01e6c5cef8fe78d11
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[16]= 3d42afad323dbfd5de4f18b20bb871b7
trained_node_hash[16]= df45ed28a9b9afd01e6c5cef8fe78d11
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.06394133, -0.87328205,  0.94261452, ...,  0.39500421,
        -0.762914  ,  0.24152084],
       [-1.31429348, -0.43025474, -0.28676832, ..., -0.23666173,
        -1.32341632, -1.35708401],
       [-1.3113524 , -0.29860849, -0.47262697, ...,  1.39863306,
        -0.09161527,  0.14555416],
       ..., 
       [ 0.75518537, -2.12073533,  1.06159465, ..., -1.00083842,
         0.52193842,  0.9648458 ],
       [ 0.21978447, -1.72758442,  1.19367969, ...,  0.93497708,
         0.37058201, -0.39562104],
       [ 0.32544459, -0.98767095,  0.70516339, ...,  0.05936922,
         0.03592098, -0.19786472]])]
Post3 self.flow[i].output_dim= 3840
data_vec [array([[ 0.06394133, -0.87328205,  0.94261452, ...,  0.39500421,
        -0.762914  ,  0.24152084],
       [-1.31429348, -0.43025474, -0.28676832, ..., -0.23666173,
        -1.32341632, -1.35708401],
       [-1.3113524 , -0.29860849, -0.47262697, ...,  1.39863306,
        -0.09161527,  0.14555416],
       ..., 
       [ 0.75518537, -2.12073533,  1.06159465, ..., -1.00083842,
         0.52193842,  0.9648458 ],
       [ 0.21978447, -1.72758442,  1.19367969, ...,  0.93497708,
         0.37058201, -0.39562104],
       [ 0.32544459, -0.98767095,  0.70516339, ...,  0.05936922,
         0.03592098, -0.19786472]])]
len(data_vec) 1
data_vec[0].shape (60000, 3840)
Training finished in 0.939 s, execution in 6.796 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #17 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[17]= e0d5433ad3ee3f31c617aebe9e8283a8
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[17]= 3d42afad323dbfd5de4f18b20bb871b7
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[17]= e0d5433ad3ee3f31c617aebe9e8283a8
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.06394133, -0.87328205,  0.94261452, ...,  0.39500421,
        -0.762914  ,  0.24152084],
       [-1.31429348, -0.43025474, -0.28676832, ..., -0.23666173,
        -1.32341632, -1.35708401],
       [-1.3113524 , -0.29860849, -0.47262697, ...,  1.39863306,
        -0.09161527,  0.14555416],
       ..., 
       [ 0.75518537, -2.12073533,  1.06159465, ..., -1.00083842,
         0.52193842,  0.9648458 ],
       [ 0.21978447, -1.72758442,  1.19367969, ...,  0.93497708,
         0.37058201, -0.39562104],
       [ 0.32544459, -0.98767095,  0.70516339, ...,  0.05936922,
         0.03592098, -0.19786472]])]
Pre_Execution of homogeneous layer with input_dim 3840 and 32 nodes
Post3 self.flow[i].output_dim= 7680
data_vec [array([[ 0.06394133, -0.87328205,  0.94261452, ...,  0.4756433 ,
         0.80534222,  0.32089555],
       [-1.31429348, -0.43025474, -0.28676832, ...,  0.31572024,
         1.25128774,  1.27668979],
       [-1.3113524 , -0.29860849, -0.47262697, ...,  1.30786534,
         0.14776592,  0.21400292],
       ..., 
       [ 0.75518537, -2.12073533,  1.06159465, ...,  1.00067068,
         0.59442274,  0.97177636],
       [ 0.21978447, -1.72758442,  1.19367969, ...,  0.9476343 ,
         0.45196777,  0.47623741],
       [ 0.32544459, -0.98767095,  0.70516339, ...,  0.10443572,
         0.06986804,  0.27358651]])]
len(data_vec) 1
data_vec[0].shape (60000, 7680)
Training finished in 7.206 s, execution in 40.944 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #18 (Layer)... of [SFANode]
untrained_node_hash[18]= fde3e5e458f765af78e54b963fea076b
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[18]= 5c3c1d06f670406eff8e142f9090e921
Searching for Trained Node: node_7680_fde3e5e458f765af78e54b963fea076b_5c3c1d06f670406eff8e142f9090e921
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_7680_fde3e5e458f765af78e54b963fea076b_5c3c1d06f670406eff8e142f9090e921.pckl
Trained node FOUND in cache...
trained_node_hash[18]= b156fd20b497ce451304312ea77666be
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.06394133, -0.87328205,  0.94261452, ...,  0.4756433 ,
         0.80534222,  0.32089555],
       [-1.31429348, -0.43025474, -0.28676832, ...,  0.31572024,
         1.25128774,  1.27668979],
       [-1.3113524 , -0.29860849, -0.47262697, ...,  1.30786534,
         0.14776592,  0.21400292],
       ..., 
       [ 0.75518537, -2.12073533,  1.06159465, ...,  1.00067068,
         0.59442274,  0.97177636],
       [ 0.21978447, -1.72758442,  1.19367969, ...,  0.9476343 ,
         0.45196777,  0.47623741],
       [ 0.32544459, -0.98767095,  0.70516339, ...,  0.10443572,
         0.06986804,  0.27358651]])]
Post3 self.flow[i].output_dim= 1920
data_vec [array([[ 0.51576874, -0.16298698, -0.15573508, ...,  0.16573072,
         1.57950766, -0.29241793],
       [-1.37128196, -0.68020867,  1.07447089, ..., -0.23569162,
        -0.58489127,  1.24503715],
       [-1.26866206, -0.33510033,  0.1279006 , ..., -0.37111612,
        -1.37932308,  0.10863907],
       ..., 
       [ 0.64941526, -2.20329402, -1.13222049, ..., -0.78943878,
        -0.25190453, -0.23897182],
       [ 0.76106175, -1.5885619 , -0.91539671, ..., -0.60217393,
         0.03840321,  1.17698076],
       [ 0.71837177, -1.11450113, -0.61424797, ..., -0.10591047,
        -0.65677578,  0.01277174]])]
len(data_vec) 1
data_vec[0].shape (60000, 1920)
Training finished in 1.508 s, execution in 19.691 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #19 (PInvSwitchboard)... untrained_node_hash[19]= 07ecf5df71ef0c9ad70acdfbd23624ab
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[19]= 865119b7a4609273cca9191dc84dfe8a
trained_node_hash[19]= 07ecf5df71ef0c9ad70acdfbd23624ab
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.51576874, -0.16298698, -0.15573508, ...,  0.16573072,
         1.57950766, -0.29241793],
       [-1.37128196, -0.68020867,  1.07447089, ..., -0.23569162,
        -0.58489127,  1.24503715],
       [-1.26866206, -0.33510033,  0.1279006 , ..., -0.37111612,
        -1.37932308,  0.10863907],
       ..., 
       [ 0.64941526, -2.20329402, -1.13222049, ..., -0.78943878,
        -0.25190453, -0.23897182],
       [ 0.76106175, -1.5885619 , -0.91539671, ..., -0.60217393,
         0.03840321,  1.17698076],
       [ 0.71837177, -1.11450113, -0.61424797, ..., -0.10591047,
        -0.65677578,  0.01277174]])]
Post3 self.flow[i].output_dim= 1920
data_vec [array([[ 0.51576874, -0.16298698, -0.15573508, ...,  0.16573072,
         1.57950766, -0.29241793],
       [-1.37128196, -0.68020867,  1.07447089, ..., -0.23569162,
        -0.58489127,  1.24503715],
       [-1.26866206, -0.33510033,  0.1279006 , ..., -0.37111612,
        -1.37932308,  0.10863907],
       ..., 
       [ 0.64941526, -2.20329402, -1.13222049, ..., -0.78943878,
        -0.25190453, -0.23897182],
       [ 0.76106175, -1.5885619 , -0.91539671, ..., -0.60217393,
         0.03840321,  1.17698076],
       [ 0.71837177, -1.11450113, -0.61424797, ..., -0.10591047,
        -0.65677578,  0.01277174]])]
len(data_vec) 1
data_vec[0].shape (60000, 1920)
Training finished in 0.581 s, execution in 2.665 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #20 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[20]= 0dcfb79e944390d28b54401490cb0181
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[20]= 865119b7a4609273cca9191dc84dfe8a
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[20]= 0dcfb79e944390d28b54401490cb0181
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.51576874, -0.16298698, -0.15573508, ...,  0.16573072,
         1.57950766, -0.29241793],
       [-1.37128196, -0.68020867,  1.07447089, ..., -0.23569162,
        -0.58489127,  1.24503715],
       [-1.26866206, -0.33510033,  0.1279006 , ..., -0.37111612,
        -1.37932308,  0.10863907],
       ..., 
       [ 0.64941526, -2.20329402, -1.13222049, ..., -0.78943878,
        -0.25190453, -0.23897182],
       [ 0.76106175, -1.5885619 , -0.91539671, ..., -0.60217393,
         0.03840321,  1.17698076],
       [ 0.71837177, -1.11450113, -0.61424797, ..., -0.10591047,
        -0.65677578,  0.01277174]])]
Pre_Execution of homogeneous layer with input_dim 1920 and 16 nodes
Post3 self.flow[i].output_dim= 3840
data_vec [array([[ 0.51576874, -0.16298698, -0.15573508, ...,  0.23742279,
         1.4415091 ,  0.37394109],
       [-1.37128196, -0.68020867,  1.07447089, ...,  0.31468448,
         0.65111861,  1.19164213],
       [-1.26866206, -0.33510033,  0.1279006 , ...,  0.45248882,
         1.29339984,  0.16935141],
       ..., 
       [ 0.64941526, -2.20329402, -1.13222049, ...,  0.82766533,
         0.33188589,  0.31818328],
       [ 0.76106175, -1.5885619 , -0.91539671, ...,  0.66646532,
         0.0737045 ,  1.1392407 ],
       [ 0.71837177, -1.11450113, -0.61424797, ...,  0.16594001,
         0.71438726,  0.03054921]])]
len(data_vec) 1
data_vec[0].shape (60000, 3840)
Training finished in 3.051 s, execution in 20.106 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #21 (Layer)... of [SFANode]
untrained_node_hash[21]= 2878597f8cef80c52285bbb672424e1e
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[21]= a9c1b90b3e8dda7ca0ac3b89485f41f3
Searching for Trained Node: node_3840_2878597f8cef80c52285bbb672424e1e_a9c1b90b3e8dda7ca0ac3b89485f41f3
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_3840_2878597f8cef80c52285bbb672424e1e_a9c1b90b3e8dda7ca0ac3b89485f41f3.pckl
Trained node FOUND in cache...
trained_node_hash[21]= 25bd88bb85a9ea027be7fd4267d0f4a4
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.51576874, -0.16298698, -0.15573508, ...,  0.23742279,
         1.4415091 ,  0.37394109],
       [-1.37128196, -0.68020867,  1.07447089, ...,  0.31468448,
         0.65111861,  1.19164213],
       [-1.26866206, -0.33510033,  0.1279006 , ...,  0.45248882,
         1.29339984,  0.16935141],
       ..., 
       [ 0.64941526, -2.20329402, -1.13222049, ...,  0.82766533,
         0.33188589,  0.31818328],
       [ 0.76106175, -1.5885619 , -0.91539671, ...,  0.66646532,
         0.0737045 ,  1.1392407 ],
       [ 0.71837177, -1.11450113, -0.61424797, ...,  0.16594001,
         0.71438726,  0.03054921]])]
Post3 self.flow[i].output_dim= 960
data_vec [array([[ 0.75663893,  0.49737903,  0.47736978, ..., -0.53025742,
         0.48804452, -0.27658474],
       [-1.20702286,  0.63553052, -1.11010426, ..., -1.42550642,
         0.32905931, -0.9839101 ],
       [-1.135892  ,  0.09958227, -0.33653032, ..., -0.00897629,
         1.22841864,  0.45858752],
       ..., 
       [ 0.69503044,  1.3161392 ,  0.62448221, ..., -0.16286197,
         0.21648292, -0.10494357],
       [-0.11988569,  1.86537135,  3.57397513, ..., -0.18077836,
         1.75192932, -0.36802533],
       [ 0.51312355,  0.9542566 ,  1.17967351, ..., -0.04511511,
        -0.15024997,  0.4537823 ]])]
len(data_vec) 1
data_vec[0].shape (60000, 960)
Training finished in 0.861 s, execution in 11.145 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #22 (PInvSwitchboard)... untrained_node_hash[22]= 68f0762fbeb9625cde2b19f50b61b30b
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[22]= 6d3564fe942317c3030b027b2149b268
trained_node_hash[22]= 68f0762fbeb9625cde2b19f50b61b30b
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.75663893,  0.49737903,  0.47736978, ..., -0.53025742,
         0.48804452, -0.27658474],
       [-1.20702286,  0.63553052, -1.11010426, ..., -1.42550642,
         0.32905931, -0.9839101 ],
       [-1.135892  ,  0.09958227, -0.33653032, ..., -0.00897629,
         1.22841864,  0.45858752],
       ..., 
       [ 0.69503044,  1.3161392 ,  0.62448221, ..., -0.16286197,
         0.21648292, -0.10494357],
       [-0.11988569,  1.86537135,  3.57397513, ..., -0.18077836,
         1.75192932, -0.36802533],
       [ 0.51312355,  0.9542566 ,  1.17967351, ..., -0.04511511,
        -0.15024997,  0.4537823 ]])]
Post3 self.flow[i].output_dim= 960
data_vec [array([[ 0.75663893,  0.49737903,  0.47736978, ..., -0.53025742,
         0.48804452, -0.27658474],
       [-1.20702286,  0.63553052, -1.11010426, ..., -1.42550642,
         0.32905931, -0.9839101 ],
       [-1.135892  ,  0.09958227, -0.33653032, ..., -0.00897629,
         1.22841864,  0.45858752],
       ..., 
       [ 0.69503044,  1.3161392 ,  0.62448221, ..., -0.16286197,
         0.21648292, -0.10494357],
       [-0.11988569,  1.86537135,  3.57397513, ..., -0.18077836,
         1.75192932, -0.36802533],
       [ 0.51312355,  0.9542566 ,  1.17967351, ..., -0.04511511,
        -0.15024997,  0.4537823 ]])]
len(data_vec) 1
data_vec[0].shape (60000, 960)
Training finished in 0.327 s, execution in 1.407 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #23 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[23]= e09e60466cb63fa1ce8e96b9c3e71683
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[23]= 6d3564fe942317c3030b027b2149b268
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[23]= e09e60466cb63fa1ce8e96b9c3e71683
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.75663893,  0.49737903,  0.47736978, ..., -0.53025742,
         0.48804452, -0.27658474],
       [-1.20702286,  0.63553052, -1.11010426, ..., -1.42550642,
         0.32905931, -0.9839101 ],
       [-1.135892  ,  0.09958227, -0.33653032, ..., -0.00897629,
         1.22841864,  0.45858752],
       ..., 
       [ 0.69503044,  1.3161392 ,  0.62448221, ..., -0.16286197,
         0.21648292, -0.10494357],
       [-0.11988569,  1.86537135,  3.57397513, ..., -0.18077836,
         1.75192932, -0.36802533],
       [ 0.51312355,  0.9542566 ,  1.17967351, ..., -0.04511511,
        -0.15024997,  0.4537823 ]])]
Pre_Execution of homogeneous layer with input_dim 960 and 8 nodes
Post3 self.flow[i].output_dim= 1920
data_vec [array([[ 0.75663893,  0.49737903,  0.47736978, ...,  0.60199017,
         0.56333606,  0.35765358],
       [-1.20702286,  0.63553052, -1.11010426, ...,  1.32793049,
         0.41097873,  0.98710724],
       [-1.135892  ,  0.09958227, -0.33653032, ...,  0.02303974,
         1.17890041,  0.53596667],
       ..., 
       [ 0.69503044,  1.3161392 ,  0.62448221, ...,  0.23412929,
         0.2939943 ,  0.16472695],
       [-0.11988569,  1.86537135,  3.57397513, ...,  0.25451721,
         1.56607756,  0.44947151],
       [ 0.51312355,  0.9542566 ,  1.17967351, ...,  0.08384123,
         0.21950858,  0.53146913]])]
len(data_vec) 1
data_vec[0].shape (60000, 1920)
Training finished in 1.528 s, execution in 10.071 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #24 (Layer)... of [SFANode]
untrained_node_hash[24]= a25ab586716cfe910c65f553c94523e5
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[24]= 1667bbec25d446ab15596143e6881ae9
Searching for Trained Node: node_1920_a25ab586716cfe910c65f553c94523e5_1667bbec25d446ab15596143e6881ae9
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_1920_a25ab586716cfe910c65f553c94523e5_1667bbec25d446ab15596143e6881ae9.pckl
Trained node FOUND in cache...
trained_node_hash[24]= f202958799dc09fc6f5ea94655749516
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.75663893,  0.49737903,  0.47736978, ...,  0.60199017,
         0.56333606,  0.35765358],
       [-1.20702286,  0.63553052, -1.11010426, ...,  1.32793049,
         0.41097873,  0.98710724],
       [-1.135892  ,  0.09958227, -0.33653032, ...,  0.02303974,
         1.17890041,  0.53596667],
       ..., 
       [ 0.69503044,  1.3161392 ,  0.62448221, ...,  0.23412929,
         0.2939943 ,  0.16472695],
       [-0.11988569,  1.86537135,  3.57397513, ...,  0.25451721,
         1.56607756,  0.44947151],
       [ 0.51312355,  0.9542566 ,  1.17967351, ...,  0.08384123,
         0.21950858,  0.53146913]])]
Post3 self.flow[i].output_dim= 480
data_vec [array([[ 0.06010682, -0.57519825,  0.53907264, ..., -0.28465076,
        -0.68293038,  0.58925031],
       [-1.00921391, -0.85245877,  0.99249138, ...,  1.18122384,
         1.57891397, -0.25878234],
       [-0.97035907, -0.47311835,  0.71561793, ..., -0.63748291,
         1.01078493,  0.9632036 ],
       ..., 
       [ 1.41662087, -0.90640468, -0.81808933, ...,  0.5038876 ,
         0.27118339, -0.04942144],
       [ 1.16267432, -1.30690762, -2.11816763, ...,  1.42266633,
        -1.39830162, -0.54804488],
       [ 1.31363148, -0.59799888, -0.44338028, ..., -0.09568493,
         0.01634075,  0.74214623]])]
len(data_vec) 1
data_vec[0].shape (60000, 480)
Training finished in 0.432 s, execution in 5.423 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #25 (PInvSwitchboard)... untrained_node_hash[25]= c4b87c889eb4e99c75d2ad3f889e8d89
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[25]= ca75d91b931067873b655acadf4b0e4f
trained_node_hash[25]= c4b87c889eb4e99c75d2ad3f889e8d89
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.06010682, -0.57519825,  0.53907264, ..., -0.28465076,
        -0.68293038,  0.58925031],
       [-1.00921391, -0.85245877,  0.99249138, ...,  1.18122384,
         1.57891397, -0.25878234],
       [-0.97035907, -0.47311835,  0.71561793, ..., -0.63748291,
         1.01078493,  0.9632036 ],
       ..., 
       [ 1.41662087, -0.90640468, -0.81808933, ...,  0.5038876 ,
         0.27118339, -0.04942144],
       [ 1.16267432, -1.30690762, -2.11816763, ...,  1.42266633,
        -1.39830162, -0.54804488],
       [ 1.31363148, -0.59799888, -0.44338028, ..., -0.09568493,
         0.01634075,  0.74214623]])]
Post3 self.flow[i].output_dim= 480
data_vec [array([[ 0.06010682, -0.57519825,  0.53907264, ..., -0.28465076,
        -0.68293038,  0.58925031],
       [-1.00921391, -0.85245877,  0.99249138, ...,  1.18122384,
         1.57891397, -0.25878234],
       [-0.97035907, -0.47311835,  0.71561793, ..., -0.63748291,
         1.01078493,  0.9632036 ],
       ..., 
       [ 1.41662087, -0.90640468, -0.81808933, ...,  0.5038876 ,
         0.27118339, -0.04942144],
       [ 1.16267432, -1.30690762, -2.11816763, ...,  1.42266633,
        -1.39830162, -0.54804488],
       [ 1.31363148, -0.59799888, -0.44338028, ..., -0.09568493,
         0.01634075,  0.74214623]])]
len(data_vec) 1
data_vec[0].shape (60000, 480)
Training finished in 0.141 s, execution in 0.658 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #26 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[26]= 4b2ee7abcccac5cbcc0a4f9fd358a365
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[26]= ffe8df826e262a7d05fabd74b17460ac
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[26]= 4b2ee7abcccac5cbcc0a4f9fd358a365
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.06010682, -0.57519825,  0.53907264, ..., -0.28465076,
        -0.68293038,  0.58925031],
       [-1.00921391, -0.85245877,  0.99249138, ...,  1.18122384,
         1.57891397, -0.25878234],
       [-0.97035907, -0.47311835,  0.71561793, ..., -0.63748291,
         1.01078493,  0.9632036 ],
       ..., 
       [ 1.41662087, -0.90640468, -0.81808933, ...,  0.5038876 ,
         0.27118339, -0.04942144],
       [ 1.16267432, -1.30690762, -2.11816763, ...,  1.42266633,
        -1.39830162, -0.54804488],
       [ 1.31363148, -0.59799888, -0.44338028, ..., -0.09568493,
         0.01634075,  0.74214623]])]
Pre_Execution of homogeneous layer with input_dim 480 and 4 nodes
Post3 self.flow[i].output_dim= 960
data_vec [array([[ 0.06010682, -0.57519825,  0.53907264, ...,  0.3659737 ,
         0.73705712,  0.65499782],
       [-1.00921391, -0.85245877,  0.99249138, ...,  1.14252514,
         1.44107563,  0.33911556],
       [-0.97035907, -0.47311835,  0.71561793, ...,  0.69754919,
         1.00861868,  0.97045294],
       ..., 
       [ 1.41662087, -0.90640468, -0.81808933, ...,  0.57791895,
         0.35205496,  0.09018459],
       [ 1.16267432, -1.30690762, -2.11816763, ...,  1.32581352,
         1.3076174 ,  0.61809168],
       [ 1.31363148, -0.59799888, -0.44338028, ...,  0.15299415,
         0.0372064 ,  0.78775576]])]
len(data_vec) 1
data_vec[0].shape (60000, 960)
Training finished in 0.409 s, execution in 4.920 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #27 (Layer)... of [SFANode]
untrained_node_hash[27]= 96534cafbc58634fed8b4624d6deab47
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[27]= 84fbdfe4253b48b7cecc82de8fa8be14
Searching for Trained Node: node_960_96534cafbc58634fed8b4624d6deab47_84fbdfe4253b48b7cecc82de8fa8be14
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_960_96534cafbc58634fed8b4624d6deab47_84fbdfe4253b48b7cecc82de8fa8be14.pckl
Trained node FOUND in cache...
trained_node_hash[27]= de8ac764afdc262993f9e8c70e3fe54a
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ 0.06010682, -0.57519825,  0.53907264, ...,  0.3659737 ,
         0.73705712,  0.65499782],
       [-1.00921391, -0.85245877,  0.99249138, ...,  1.14252514,
         1.44107563,  0.33911556],
       [-0.97035907, -0.47311835,  0.71561793, ...,  0.69754919,
         1.00861868,  0.97045294],
       ..., 
       [ 1.41662087, -0.90640468, -0.81808933, ...,  0.57791895,
         0.35205496,  0.09018459],
       [ 1.16267432, -1.30690762, -2.11816763, ...,  1.32581352,
         1.3076174 ,  0.61809168],
       [ 1.31363148, -0.59799888, -0.44338028, ...,  0.15299415,
         0.0372064 ,  0.78775576]])]
Post3 self.flow[i].output_dim= 240
data_vec [array([[ -2.23913749e-01,   6.04032775e-01,  -3.80057631e-01, ...,
         -6.39578090e-01,  -1.21594646e+00,   6.28670545e-01],
       [ -6.44806270e-01,  -8.81371062e-01,  -9.72180919e-01, ...,
          9.60835569e-01,  -1.20180376e+00,   6.91202020e-01],
       [ -5.88111741e-01,  -2.66591097e-01,  -9.47135367e-01, ...,
          6.19684734e-01,  -8.14327206e-01,  -4.53625816e-01],
       ..., 
       [  1.57472575e+00,  -1.17759189e+00,   1.42147302e+00, ...,
          1.23809865e+00,  -3.47768679e-01,  -1.38252930e+00],
       [  1.64062758e+00,  -1.80632101e+00,   2.35518193e+00, ...,
         -3.43332267e-02,  -5.40217398e-01,   6.39621922e-02],
       [  1.27803118e+00,  -7.01427569e-01,   1.10212498e+00, ...,
          1.22902557e-03,   1.15053958e-01,   9.03788749e-01]])]
len(data_vec) 1
data_vec[0].shape (60000, 240)
Training finished in 0.220 s, execution in 3.223 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #28 (PInvSwitchboard)... untrained_node_hash[28]= fe00bd4063b06535febffcd3c64bdd27
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[28]= 613f7d7c79e2704fb209635c36af9359
trained_node_hash[28]= fe00bd4063b06535febffcd3c64bdd27
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ -2.23913749e-01,   6.04032775e-01,  -3.80057631e-01, ...,
         -6.39578090e-01,  -1.21594646e+00,   6.28670545e-01],
       [ -6.44806270e-01,  -8.81371062e-01,  -9.72180919e-01, ...,
          9.60835569e-01,  -1.20180376e+00,   6.91202020e-01],
       [ -5.88111741e-01,  -2.66591097e-01,  -9.47135367e-01, ...,
          6.19684734e-01,  -8.14327206e-01,  -4.53625816e-01],
       ..., 
       [  1.57472575e+00,  -1.17759189e+00,   1.42147302e+00, ...,
          1.23809865e+00,  -3.47768679e-01,  -1.38252930e+00],
       [  1.64062758e+00,  -1.80632101e+00,   2.35518193e+00, ...,
         -3.43332267e-02,  -5.40217398e-01,   6.39621922e-02],
       [  1.27803118e+00,  -7.01427569e-01,   1.10212498e+00, ...,
          1.22902557e-03,   1.15053958e-01,   9.03788749e-01]])]
Post3 self.flow[i].output_dim= 240
data_vec [array([[ -2.23913749e-01,   6.04032775e-01,  -3.80057631e-01, ...,
         -6.39578090e-01,  -1.21594646e+00,   6.28670545e-01],
       [ -6.44806270e-01,  -8.81371062e-01,  -9.72180919e-01, ...,
          9.60835569e-01,  -1.20180376e+00,   6.91202020e-01],
       [ -5.88111741e-01,  -2.66591097e-01,  -9.47135367e-01, ...,
          6.19684734e-01,  -8.14327206e-01,  -4.53625816e-01],
       ..., 
       [  1.57472575e+00,  -1.17759189e+00,   1.42147302e+00, ...,
          1.23809865e+00,  -3.47768679e-01,  -1.38252930e+00],
       [  1.64062758e+00,  -1.80632101e+00,   2.35518193e+00, ...,
         -3.43332267e-02,  -5.40217398e-01,   6.39621922e-02],
       [  1.27803118e+00,  -7.01427569e-01,   1.10212498e+00, ...,
          1.22902557e-03,   1.15053958e-01,   9.03788749e-01]])]
len(data_vec) 1
data_vec[0].shape (60000, 240)
Training finished in 0.080 s, execution in 0.411 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #29 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[29]= c51f9e68bc42da389104aa3b437ca9f8
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[29]= 613f7d7c79e2704fb209635c36af9359
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[29]= c51f9e68bc42da389104aa3b437ca9f8
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[ -2.23913749e-01,   6.04032775e-01,  -3.80057631e-01, ...,
         -6.39578090e-01,  -1.21594646e+00,   6.28670545e-01],
       [ -6.44806270e-01,  -8.81371062e-01,  -9.72180919e-01, ...,
          9.60835569e-01,  -1.20180376e+00,   6.91202020e-01],
       [ -5.88111741e-01,  -2.66591097e-01,  -9.47135367e-01, ...,
          6.19684734e-01,  -8.14327206e-01,  -4.53625816e-01],
       ..., 
       [  1.57472575e+00,  -1.17759189e+00,   1.42147302e+00, ...,
          1.23809865e+00,  -3.47768679e-01,  -1.38252930e+00],
       [  1.64062758e+00,  -1.80632101e+00,   2.35518193e+00, ...,
         -3.43332267e-02,  -5.40217398e-01,   6.39621922e-02],
       [  1.27803118e+00,  -7.01427569e-01,   1.10212498e+00, ...,
          1.22902557e-03,   1.15053958e-01,   9.03788749e-01]])]
Pre_Execution of homogeneous layer with input_dim 240 and 2 nodes
Post3 self.flow[i].output_dim= 480
data_vec [array([[-0.22391375,  0.60403278, -0.38005763, ...,  0.69938266,
         1.16931511,  0.6898243 ],
       [-0.64480627, -0.88137106, -0.97218092, ...,  0.96854378,
         1.15842213,  0.74419029],
       [-0.58811174, -0.2665911 , -0.94713537, ...,  0.68192504,
         0.84847521,  0.5313225 ],
       ..., 
       [ 1.57472575, -1.17759189,  1.42147302, ...,  1.18632642,
         0.42956845,  1.29580447],
       [ 1.64062758, -1.80632101,  2.35518193, ...,  0.06738631,
         0.61101919,  0.11085076],
       [ 1.27803118, -0.70142757,  1.10212498, ...,  0.00469514,
         0.17730511,  0.92226036]])]
len(data_vec) 1
data_vec[0].shape (60000, 480)
Training finished in 0.310 s, execution in 2.575 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #30 (Layer)... of [SFANode]
untrained_node_hash[30]= ededdfbdcdf802cd5bd30a04f74f6e3e
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[30]= a980a2946ba2ec179a279ca8b2750884
Searching for Trained Node: node_480_ededdfbdcdf802cd5bd30a04f74f6e3e_a980a2946ba2ec179a279ca8b2750884
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_480_ededdfbdcdf802cd5bd30a04f74f6e3e_a980a2946ba2ec179a279ca8b2750884.pckl
Trained node FOUND in cache...
trained_node_hash[30]= d94295b57ed2fbe1517b722316b3c948
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.22391375,  0.60403278, -0.38005763, ...,  0.69938266,
         1.16931511,  0.6898243 ],
       [-0.64480627, -0.88137106, -0.97218092, ...,  0.96854378,
         1.15842213,  0.74419029],
       [-0.58811174, -0.2665911 , -0.94713537, ...,  0.68192504,
         0.84847521,  0.5313225 ],
       ..., 
       [ 1.57472575, -1.17759189,  1.42147302, ...,  1.18632642,
         0.42956845,  1.29580447],
       [ 1.64062758, -1.80632101,  2.35518193, ...,  0.06738631,
         0.61101919,  0.11085076],
       [ 1.27803118, -0.70142757,  1.10212498, ...,  0.00469514,
         0.17730511,  0.92226036]])]
Post3 self.flow[i].output_dim= 120
data_vec [array([[-0.73601114,  0.87068576, -2.25301092, ...,  0.78389743,
         0.10899787,  0.16416584],
       [-0.85774161,  0.7219628 , -0.66048136, ...,  0.56054848,
         0.93060179,  0.74397356],
       [-1.36651055,  1.0545046 , -0.92489576, ..., -0.35649726,
         0.48874578, -0.29211003],
       ..., 
       [ 0.78881675,  0.51725003,  1.20393588, ..., -0.69029929,
        -0.28867891, -0.70571904],
       [ 0.95297958,  0.8879773 ,  1.2146429 , ..., -0.58068442,
         0.56864148, -0.30674086],
       [ 1.22540286,  0.91900803,  1.31709338, ..., -0.36245324,
        -0.24376607, -0.88717623]])]
len(data_vec) 1
data_vec[0].shape (60000, 120)
Training finished in 0.104 s, execution in 1.062 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #31 (PInvSwitchboard)... untrained_node_hash[31]= 7ae3303898fe5c308691d487fc0df46d
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[31]= 63c5c7d8f8cdff036648efe613416e3c
trained_node_hash[31]= 7ae3303898fe5c308691d487fc0df46d
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.73601114,  0.87068576, -2.25301092, ...,  0.78389743,
         0.10899787,  0.16416584],
       [-0.85774161,  0.7219628 , -0.66048136, ...,  0.56054848,
         0.93060179,  0.74397356],
       [-1.36651055,  1.0545046 , -0.92489576, ..., -0.35649726,
         0.48874578, -0.29211003],
       ..., 
       [ 0.78881675,  0.51725003,  1.20393588, ..., -0.69029929,
        -0.28867891, -0.70571904],
       [ 0.95297958,  0.8879773 ,  1.2146429 , ..., -0.58068442,
         0.56864148, -0.30674086],
       [ 1.22540286,  0.91900803,  1.31709338, ..., -0.36245324,
        -0.24376607, -0.88717623]])]
Post3 self.flow[i].output_dim= 120
data_vec [array([[-0.73601114,  0.87068576, -2.25301092, ...,  0.78389743,
         0.10899787,  0.16416584],
       [-0.85774161,  0.7219628 , -0.66048136, ...,  0.56054848,
         0.93060179,  0.74397356],
       [-1.36651055,  1.0545046 , -0.92489576, ..., -0.35649726,
         0.48874578, -0.29211003],
       ..., 
       [ 0.78881675,  0.51725003,  1.20393588, ..., -0.69029929,
        -0.28867891, -0.70571904],
       [ 0.95297958,  0.8879773 ,  1.2146429 , ..., -0.58068442,
         0.56864148, -0.30674086],
       [ 1.22540286,  0.91900803,  1.31709338, ..., -0.36245324,
        -0.24376607, -0.88717623]])]
len(data_vec) 1
data_vec[0].shape (60000, 120)
Training finished in 0.039 s, execution in 0.161 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #32 (CloneLayer)... of [GeneralExpansionNode]
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
untrained_node_hash[32]= 52c8fbef5d94be8afd77f88557d2a99d
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[32]= 63c5c7d8f8cdff036648efe613416e3c
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
Ignoring length 144 dictionary
trained_node_hash[32]= 52c8fbef5d94be8afd77f88557d2a99d
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.73601114,  0.87068576, -2.25301092, ...,  0.78389743,
         0.10899787,  0.16416584],
       [-0.85774161,  0.7219628 , -0.66048136, ...,  0.56054848,
         0.93060179,  0.74397356],
       [-1.36651055,  1.0545046 , -0.92489576, ..., -0.35649726,
         0.48874578, -0.29211003],
       ..., 
       [ 0.78881675,  0.51725003,  1.20393588, ..., -0.69029929,
        -0.28867891, -0.70571904],
       [ 0.95297958,  0.8879773 ,  1.2146429 , ..., -0.58068442,
         0.56864148, -0.30674086],
       [ 1.22540286,  0.91900803,  1.31709338, ..., -0.36245324,
        -0.24376607, -0.88717623]])]
Pre_Execution of homogeneous layer with input_dim 120 and 1 nodes
Post3 self.flow[i].output_dim= 240
data_vec [array([[-0.73601114,  0.87068576, -2.25301092, ...,  0.82301432,
         0.16979872,  0.23562764],
       [-0.85774161,  0.7219628 , -0.66048136, ...,  0.62934755,
         0.94408502,  0.78930709],
       [-1.36651055,  1.0545046 , -0.92489576, ...,  0.43817234,
         0.56398352,  0.37362608],
       ..., 
       [ 0.78881675,  0.51725003,  1.20393588, ...,  0.74341264,
         0.37011105,  0.75666817],
       [ 0.95297958,  0.8879773 ,  1.2146429 , ...,  0.64736936,
         0.63660615,  0.38852351],
       [ 1.22540286,  0.91900803,  1.31709338, ...,  0.44401903,
         0.32327982,  0.90867361]])]
len(data_vec) 1
data_vec[0].shape (60000, 240)
Training finished in 0.150 s, execution in 1.320 s
funcs_sets is: [[<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>], [<function <lambda> at 0x22cdf50>]]
param_sets = [[{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}], [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]]
node_funcs and node_params: [<function <lambda> at 0x22cdf50>] [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
new_node_funcs =  [<function <lambda> at 0x22cdf50>]
*****************************************************************
Training node #33 (Layer)... of [SFANode]
untrained_node_hash[33]= aefb37def0b8e08f03d89e9e5a965050
node_params to be hashed:  [{'include_latest': False, 'train_mode': 'fwindow16', 'block_size': 1200, 'n_parallel': 2, 'scheduler': None}]
data_in_hash[33]= dca7b2856464eaaa2bd769e836fe17a4
Searching for Trained Node: node_240_aefb37def0b8e08f03d89e9e5a965050_dca7b2856464eaaa2bd769e836fe17a4
Looking for file: /local/tmp/escalafl/Alberto/SavedNodes/node_240_aefb37def0b8e08f03d89e9e5a965050_dca7b2856464eaaa2bd769e836fe17a4.pckl
Trained node FOUND in cache...
trained_node_hash[33]= 2dd0ff62789ddd55329ff0c4d53819fe
++++++++++++++++++++++++++++++++++++ Executing...
data_vect is: [array([[-0.73601114,  0.87068576, -2.25301092, ...,  0.82301432,
         0.16979872,  0.23562764],
       [-0.85774161,  0.7219628 , -0.66048136, ...,  0.62934755,
         0.94408502,  0.78930709],
       [-1.36651055,  1.0545046 , -0.92489576, ...,  0.43817234,
         0.56398352,  0.37362608],
       ..., 
       [ 0.78881675,  0.51725003,  1.20393588, ...,  0.74341264,
         0.37011105,  0.75666817],
       [ 0.95297958,  0.8879773 ,  1.2146429 , ...,  0.64736936,
         0.63660615,  0.38852351],
       [ 1.22540286,  0.91900803,  1.31709338, ...,  0.44401903,
         0.32327982,  0.90867361]])]
Post3 self.flow[i].output_dim= 60
data_vec [array([[-0.55084705, -1.37578114,  2.20620495, ...,  0.51644319,
        -0.02815224, -0.09392322],
       [-0.5254498 , -0.60478159,  0.54633643, ...,  0.6264479 ,
         0.44036086, -0.625614  ],
       [-1.03686801, -0.75771378,  0.92087204, ...,  0.05614013,
        -0.24177929, -0.30882507],
       ..., 
       [ 0.33865837, -0.74868467, -1.31098794, ..., -0.41244946,
        -0.02607295, -0.5632409 ],
       [ 0.96789116, -1.24207458, -1.75344918, ..., -0.20003632,
        -0.13014102,  0.76416183],
       [ 0.85379835, -1.03850019, -1.66588975, ...,  0.08288773,
         0.11280478,  0.07071148]])]
len(data_vec) 1
data_vec[0].shape (60000, 60)
Training finished in 0.058 s, execution in 0.296 s
sl_seq is [[-0.55084705 -1.37578114  2.20620495 ...,  0.51644319 -0.02815224
  -0.09392322]
 [-0.5254498  -0.60478159  0.54633643 ...,  0.6264479   0.44036086
  -0.625614  ]
 [-1.03686801 -0.75771378  0.92087204 ...,  0.05614013 -0.24177929
  -0.30882507]
 ..., 
 [ 0.33865837 -0.74868467 -1.31098794 ..., -0.41244946 -0.02607295
  -0.5632409 ]
 [ 0.96789116 -1.24207458 -1.75344918 ..., -0.20003632 -0.13014102
   0.76416183]
 [ 0.85379835 -1.03850019 -1.66588975 ...,  0.08288773  0.11280478
   0.07071148]]
Network trained (specialized way) in time 1695.465 s
Polarization of 29 SFA Signals Corrected!!!
Bias updated
Saving Finished
Done creating / training / loading network
(1, 60)
Flow has 34 nodes
0
PInvSwitchboard
16384
16384
0
Node[0] is PInvSwitchboard, has input_dim=16384, output_dim=16384 and size=0
1
Layer
16384
13312
212992
Node[1] is Layer, has input_dim=16384, output_dim=13312 and size=212992
   contains 1024 nodes of type PCANode, each with input_dim=16, output_dim=13
2
CloneLayer
13312
26624
0
Node[2] is CloneLayer, has input_dim=13312, output_dim=26624 and size=0
   contains 1024 cloned nodes of type GeneralExpansionNode, each with input_dim=13, output_dim=26
3
Layer
26624
13312
346112
Node[3] is Layer, has input_dim=26624, output_dim=13312 and size=346112
   contains 1024 nodes of type SFANode, each with input_dim=26, output_dim=13
4
PInvSwitchboard
13312
13312
0
Node[4] is PInvSwitchboard, has input_dim=13312, output_dim=13312 and size=0
5
CloneLayer
13312
26624
0
Node[5] is CloneLayer, has input_dim=13312, output_dim=26624 and size=0
   contains 512 cloned nodes of type GeneralExpansionNode, each with input_dim=26, output_dim=52
6
Layer
26624
10240
532480
Node[6] is Layer, has input_dim=26624, output_dim=10240 and size=532480
   contains 512 nodes of type SFANode, each with input_dim=52, output_dim=20
7
PInvSwitchboard
10240
10240
0
Node[7] is PInvSwitchboard, has input_dim=10240, output_dim=10240 and size=0
8
CloneLayer
10240
20480
0
Node[8] is CloneLayer, has input_dim=10240, output_dim=20480 and size=0
   contains 256 cloned nodes of type GeneralExpansionNode, each with input_dim=40, output_dim=80
9
Layer
20480
8960
716800
Node[9] is Layer, has input_dim=20480, output_dim=8960 and size=716800
   contains 256 nodes of type SFANode, each with input_dim=80, output_dim=35
10
PInvSwitchboard
8960
8960
0
Node[10] is PInvSwitchboard, has input_dim=8960, output_dim=8960 and size=0
11
CloneLayer
8960
17920
0
Node[11] is CloneLayer, has input_dim=8960, output_dim=17920 and size=0
   contains 128 cloned nodes of type GeneralExpansionNode, each with input_dim=70, output_dim=140
12
Layer
17920
7680
1075200
Node[12] is Layer, has input_dim=17920, output_dim=7680 and size=1075200
   contains 128 nodes of type SFANode, each with input_dim=140, output_dim=60
13
PInvSwitchboard
7680
7680
0
Node[13] is PInvSwitchboard, has input_dim=7680, output_dim=7680 and size=0
14
CloneLayer
7680
15360
0
Node[14] is CloneLayer, has input_dim=7680, output_dim=15360 and size=0
   contains 64 cloned nodes of type GeneralExpansionNode, each with input_dim=120, output_dim=240
15
Layer
15360
3840
921600
Node[15] is Layer, has input_dim=15360, output_dim=3840 and size=921600
   contains 64 nodes of type SFANode, each with input_dim=240, output_dim=60
16
PInvSwitchboard
3840
3840
0
Node[16] is PInvSwitchboard, has input_dim=3840, output_dim=3840 and size=0
17
CloneLayer
3840
7680
0
Node[17] is CloneLayer, has input_dim=3840, output_dim=7680 and size=0
   contains 32 cloned nodes of type GeneralExpansionNode, each with input_dim=120, output_dim=240
18
Layer
7680
1920
460800
Node[18] is Layer, has input_dim=7680, output_dim=1920 and size=460800
   contains 32 nodes of type SFANode, each with input_dim=240, output_dim=60
19
PInvSwitchboard
1920
1920
0
Node[19] is PInvSwitchboard, has input_dim=1920, output_dim=1920 and size=0
20
CloneLayer
1920
3840
0
Node[20] is CloneLayer, has input_dim=1920, output_dim=3840 and size=0
   contains 16 cloned nodes of type GeneralExpansionNode, each with input_dim=120, output_dim=240
21
Layer
3840
960
230400
Node[21] is Layer, has input_dim=3840, output_dim=960 and size=230400
   contains 16 nodes of type SFANode, each with input_dim=240, output_dim=60
22
PInvSwitchboard
960
960
0
Node[22] is PInvSwitchboard, has input_dim=960, output_dim=960 and size=0
23
CloneLayer
960
1920
0
Node[23] is CloneLayer, has input_dim=960, output_dim=1920 and size=0
   contains 8 cloned nodes of type GeneralExpansionNode, each with input_dim=120, output_dim=240
24
Layer
1920
480
115200
Node[24] is Layer, has input_dim=1920, output_dim=480 and size=115200
   contains 8 nodes of type SFANode, each with input_dim=240, output_dim=60
25
PInvSwitchboard
480
480
0
Node[25] is PInvSwitchboard, has input_dim=480, output_dim=480 and size=0
26
CloneLayer
480
960
0
Node[26] is CloneLayer, has input_dim=480, output_dim=960 and size=0
   contains 4 cloned nodes of type GeneralExpansionNode, each with input_dim=120, output_dim=240
27
Layer
960
240
57600
Node[27] is Layer, has input_dim=960, output_dim=240 and size=57600
   contains 4 nodes of type SFANode, each with input_dim=240, output_dim=60
28
PInvSwitchboard
240
240
0
Node[28] is PInvSwitchboard, has input_dim=240, output_dim=240 and size=0
29
CloneLayer
240
480
0
Node[29] is CloneLayer, has input_dim=240, output_dim=480 and size=0
   contains 2 cloned nodes of type GeneralExpansionNode, each with input_dim=120, output_dim=240
30
Layer
480
120
28800
Node[30] is Layer, has input_dim=480, output_dim=120 and size=28800
   contains 2 nodes of type SFANode, each with input_dim=240, output_dim=60
31
PInvSwitchboard
120
120
0
Node[31] is PInvSwitchboard, has input_dim=120, output_dim=120 and size=0
32
CloneLayer
120
240
0
Node[32] is CloneLayer, has input_dim=120, output_dim=240 and size=0
   contains 1 cloned nodes of type GeneralExpansionNode, each with input_dim=120, output_dim=240
33
Layer
240
60
14400
Node[33] is Layer, has input_dim=240, output_dim=60 and size=14400
   contains 1 nodes of type SFANode, each with input_dim=240, output_dim=60
Total flow size: 4712384
Largest node size: 14400
Displaying eigenvalues of SFA Nodes in flow of length 34
Node 3 is a Layer, and its first SFANode has d= [ 1.81653609  1.89300007  1.97602558  1.98645248  1.98736772  1.98801439
  1.98985792  1.99221361  1.99263745  1.99409589  1.99558897  1.9976594
  1.99926659]
Node 6 is a Layer, and its first SFANode has d= [ 1.63121086  1.83938555  1.96416505  1.97121084  1.97476819  1.97722288
  1.97785563  1.98052084  1.98166768  1.98239174  1.98341833  1.98412447
  1.98434581  1.98610108  1.98676994  1.98742673  1.98856393  1.98944448
  1.9899229   1.99171694]
Node 9 is a Layer, and its first SFANode has d= [ 1.53735972  1.78391771  1.94314683  1.95727905  1.95960046  1.96205527
  1.96462238  1.96557546  1.96653797  1.96779873  1.96885384  1.9707836
  1.97122215  1.97166808  1.97205579  1.97418205  1.97432853  1.9754778
  1.9761998   1.97693915  1.97797819  1.97889013  1.97954862  1.98081862
  1.98115856  1.9824921   1.98301705  1.98387082  1.98451737  1.98549511
  1.9868605   1.98728683  1.98755877  1.98830651  1.98911182]
Node 12 is a Layer, and its first SFANode has d= [ 1.42903689  1.69190558  1.90736017  1.93123952  1.93496639  1.93852273
  1.94092741  1.94255545  1.94454687  1.94639552  1.94694287  1.94854494
  1.94902696  1.95027538  1.95114272  1.95187536  1.95282919  1.95449447
  1.95594126  1.95696034  1.95741892  1.95909442  1.96028837  1.96172867
  1.96226201  1.96352588  1.96363688  1.96443043  1.96520326  1.96589759
  1.96619586  1.9671247   1.96738356  1.96852122  1.96893369  1.96964511
  1.96990674  1.97071137  1.97112237  1.97147972  1.97344533  1.97394614
  1.97487962  1.97545178  1.97582993  1.97677018  1.97720437  1.97785467
  1.97862556  1.97887659  1.97989437  1.98047292  1.98065244  1.98127892
  1.98212009  1.98243653  1.98285294  1.98327619  1.98434994  1.98462889]
Node 15 is a Layer, and its first SFANode has d= [ 1.28423619  1.57495233  1.84843511  1.89329925  1.90244037  1.90383096
  1.90942609  1.9130942   1.91454848  1.91503197  1.91736753  1.91919905
  1.92039672  1.92096826  1.922592    1.92341365  1.92591607  1.92731966
  1.92808246  1.92889256  1.92934015  1.92998644  1.93097417  1.9316033
  1.93314184  1.93373567  1.93503191  1.9364427   1.93676402  1.93736991
  1.9387295   1.93935662  1.94034402  1.94151749  1.94174148  1.94281277
  1.94349917  1.94378604  1.94399074  1.94553699  1.9458115   1.94655326
  1.94665488  1.94739238  1.94810858  1.94915816  1.94980237  1.95053612
  1.95113829  1.95132841  1.95200638  1.95265197  1.95336707  1.95378262
  1.95424155  1.95485878  1.95563195  1.95619316  1.9569589   1.95737386]
Node 18 is a Layer, and its first SFANode has d= [ 1.13155277  1.39070396  1.73055455  1.82793213  1.84327276  1.85492477
  1.85611501  1.87149237  1.87444202  1.87865269  1.8811722   1.88566652
  1.88691948  1.89015376  1.89203589  1.89343844  1.89458079  1.89579115
  1.89660625  1.89784931  1.89846945  1.89939622  1.90323563  1.904107
  1.9042871   1.90508797  1.90600723  1.9068431   1.90704213  1.90854163
  1.90992538  1.91181758  1.91291373  1.9133924   1.91550362  1.9157466
  1.91705058  1.91834726  1.91863684  1.91973375  1.92023096  1.92106094
  1.92193977  1.92254667  1.92325005  1.92465379  1.92495215  1.92527336
  1.92637699  1.92706487  1.92711449  1.92807513  1.92990515  1.930682
  1.93109073  1.93126261  1.93242754  1.93335497  1.93360353  1.93450162]
Node 21 is a Layer, and its first SFANode has d= [ 0.94809929  1.15830462  1.47007974  1.65132645  1.73383688  1.77364204
  1.78044877  1.79138011  1.80243222  1.81579664  1.81880006  1.82950675
  1.83301542  1.83544255  1.83630491  1.84208148  1.84584481  1.84682081
  1.84998508  1.85056687  1.85168203  1.85820555  1.8582801   1.86339796
  1.86485237  1.86579695  1.86662423  1.86902131  1.87063096  1.87132341
  1.87289869  1.87566074  1.87717373  1.87757207  1.87978863  1.88112885
  1.88320676  1.8840759   1.88587674  1.88739873  1.88902862  1.89045606
  1.89170265  1.89308644  1.89433517  1.8948776   1.89639155  1.89762275
  1.89783702  1.898664    1.90023347  1.90091821  1.90196077  1.90273144
  1.90366869  1.90459454  1.90541347  1.90635578  1.90751769  1.90957288]
Node 24 is a Layer, and its first SFANode has d= [ 0.76370173  0.88400153  1.06669737  1.31490232  1.51619603  1.59575736
  1.67289711  1.69932399  1.74410991  1.75129012  1.75979098  1.77274815
  1.77451686  1.7823891   1.79002489  1.79436258  1.80097952  1.80492683
  1.81042699  1.81212426  1.81670168  1.8217004   1.82401     1.82640086
  1.82821307  1.83020777  1.83229295  1.83364805  1.83639543  1.83710579
  1.83901136  1.84076986  1.84359115  1.844315    1.84606506  1.84814547
  1.84952428  1.85032376  1.85183941  1.85363116  1.85534798  1.85651528
  1.85704055  1.85883456  1.86088313  1.86223069  1.8643506   1.8644742
  1.86538427  1.86659164  1.86731016  1.86820931  1.87040077  1.87072024
  1.87175899  1.87337285  1.87350201  1.87504603  1.8760583   1.87829975]
Node 27 is a Layer, and its first SFANode has d= [ 0.52999977  0.64204616  0.7472588   0.9469943   1.05226425  1.17579024
  1.30985199  1.39725273  1.52231036  1.5651885   1.59472201  1.62311604
  1.65614441  1.66765496  1.66858644  1.68743191  1.69188318  1.70681093
  1.71538565  1.71741449  1.72522121  1.72725689  1.73722252  1.73956613
  1.74982133  1.7524962   1.75577539  1.75954818  1.76563309  1.76972741
  1.7707472   1.77693879  1.7812502   1.78252508  1.78610932  1.7901399
  1.79098192  1.79465907  1.79691021  1.8020832   1.8052926   1.80750985
  1.80822792  1.80978451  1.81410244  1.81512056  1.81714092  1.81848529
  1.82359302  1.82488564  1.82884363  1.82964651  1.83098176  1.83286667
  1.83438161  1.83848438  1.84060591  1.84166846  1.84315742  1.8454385 ]
Node 30 is a Layer, and its first SFANode has d= [ 0.33175545  0.42087878  0.50803205  0.67325146  0.81109141  0.88456242
  0.97093842  1.07772998  1.17801069  1.28412037  1.3463533   1.41248038
  1.44185681  1.49110638  1.50992841  1.53870355  1.55825775  1.56346337
  1.57457653  1.58426977  1.59615173  1.60393871  1.61342206  1.61740848
  1.63304332  1.64057268  1.6445008   1.64764641  1.64933423  1.65362121
  1.65799936  1.66142898  1.66716698  1.66882303  1.67038693  1.67362182
  1.67683039  1.67874654  1.68241324  1.68657501  1.68709817  1.69479411
  1.69627965  1.69795163  1.70030442  1.70350915  1.70834945  1.7112903
  1.71549754  1.71846781  1.71927016  1.72056921  1.72425993  1.72779124
  1.72985851  1.73381762  1.73750228  1.73930207  1.74240523  1.74863649]
Node 33 is a Layer, and its first SFANode has d= [ 0.22659581  0.26288789  0.35644188  0.43843798  0.61336966  0.62138312
  0.78434659  0.81797558  0.97771339  1.02563132  1.15624631  1.16255688
  1.29476792  1.31630127  1.32780922  1.40442332  1.42879809  1.43582047
  1.44908813  1.47210318  1.47519234  1.48186578  1.4982347   1.50453323
  1.50993596  1.52097884  1.52188346  1.53287401  1.53785532  1.53847141
  1.54181252  1.54653619  1.54888422  1.55110911  1.5524435   1.55654834
  1.56333866  1.56526155  1.57027558  1.57372905  1.58117155  1.58472657
  1.588063    1.59178733  1.59262917  1.59840791  1.60657827  1.60879392
  1.61187937  1.61713989  1.61989962  1.62728088  1.63234302  1.63360262
  1.63856627  1.64115386  1.64677552  1.65212094  1.65858667  1.66384952]
hierarchy_out_dim (real output data) = 60
last_node_out_dim= 60
last_Layer_node_out_dim= 60
last node of network is a layer! is this a mistake?
Computing typical delta, eta values for Train SFA Signal
typical_delta_train= [ 0.23719875  0.28585042  0.38635444  0.50453169  0.70724313  0.74619271
  0.94300606  1.00671565  1.14866905  1.23030564  1.39561968  1.47345585
  1.64514417  1.64604222  1.56422247  1.65101796  1.56190785  1.36673835
  1.24569179  1.70503112  1.42249492  1.70742857  1.47709805  2.32740858
  1.40215778  1.45176904  2.27883966  1.53144453  1.79949493  1.57376891
  2.41312589  1.7464905   1.90228354  2.2765365   1.72700127  1.75419516
  1.82312205  2.19863575  2.57516558  2.00764884  1.6532924   1.86132804
  2.21792244  2.08622691  1.84732096  1.82612734  1.2359028   2.07769261
  1.62066747  1.60070788  1.68465276  1.42355126  2.08773872  1.9080544
  1.69636493  1.71757935  2.24227706  1.73879098  1.73328862  1.76741256]
computed delta/eta in 589.124 ms
Setting correct classes and labels for the Classifier/Regression, Train SFA Signal
Loading test images, seen ids...
LOADING KNOWNID TEST INFORMATION
Loading  50000 Images: width=256, height=192  subimage_width=128,subimage_height=128
color_background_filter is: None
50000  Images loaded in 153.765 s
Execution over known id testing set...
Input Signal: Known Id test images
Execution over Known Id in 1003.733 s
Computing typical delta, eta values for Seen Id SFA Signal
sl_seq_seenid= [[-0.87046499 -1.19128763 -1.57903901 ...,  0.97808764  0.31052061
  -0.51951969]
 [-0.61135173 -0.83314533 -0.963879   ..., -2.37258701  1.06464385
  -0.67547232]
 [-1.38587008 -1.09044079 -0.30943234 ..., -0.78424456  0.75855888
   0.89837307]
 ..., 
 [ 0.87722064 -0.55999371  0.69746977 ...,  0.40533965 -0.20754427
  -0.43653748]
 [ 1.05737336 -1.1920073   1.78463475 ..., -0.37775509 -0.54136212
  -0.92606475]
 [ 1.12878632 -0.89589924  1.14103815 ..., -0.44592912  0.89179199
  -0.2248734 ]]
typical delta_seenid= [ 0.24907599  0.28996797  0.40640791  0.5063376   0.69147443  0.73689774
  0.89576152  0.96880755  1.11222571  1.21030118  1.24897828  1.3496025
  1.32539143  1.33890912  0.50676435  1.26647717  1.12633299  0.46479666
  0.62005447  0.69672685  0.78538487  0.56408545  0.55988026  0.61566971
  0.52265928  0.5994725   0.69597944  0.60497036  0.5796538   0.54471249
  0.5274367   0.65385724  0.70750313  0.58423497  0.57594623  0.62638328
  0.58120571  0.66271379  0.69441609  0.72508935  0.64258595  0.7084795
  0.7333003   0.73921885  0.87704598  0.747666    0.71268751  0.91524096
  0.65610984  0.66968073  0.74719124  0.70146928  0.80184687  0.90841084
  0.92081297  0.92928892  0.92371222  0.99767466  0.9317473   0.98552497]
typical eta_seenid= [ 3.93717665  4.24976747  5.03707845  5.6253551   6.56750222  6.77823177
  7.47270605  7.7883633   8.33466605  8.69555519  8.83065113  9.17059236
  9.08526435  9.13253728  5.58381054  8.88286165  8.37630893  5.33583595
  6.17315391  6.57303672  6.99387021  5.90284318  5.88115458  6.14321221
  5.67926537  6.10514266  6.54745516  6.10867913  5.97815686  5.79265902
  5.71434143  6.34786657  6.61122948  5.98920733  5.93957343  6.20367109
  5.9744571   6.40735667  6.54792517  6.68126447  6.30453593  6.59541886
  6.71739359  6.7324251   7.37525435  6.77990986  6.62011294  7.52818732
  6.36301115  6.41681301  6.80452338  6.58081068  7.03590613  7.45648761
  7.53107205  7.56245058  7.54783366  7.8194806   7.54105691  7.79362345]
computed delta/eta in 487.439 ms
Setting correct labels/classes data for seenid
*** Training Classifier/Regression
Training Classifier/Regression GC...
Training SVM...
SVM.parameters: <svm.svm_parameter object at 0x2175f80>
Executing/Executed over training set...
Input Signal: Training Data
Classification/Regression over training set...
GC classify...
value.shape= (60000,)
labels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
acc_probs[0:5] [[  8.58363559e-01   9.86317129e-01   9.99944231e-01   9.99999998e-01
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00]
 [  3.00907507e-01   5.56221372e-01   7.96787592e-01   9.01135154e-01
    9.70028026e-01   9.93005484e-01   9.98486874e-01   9.99957405e-01
    9.99981948e-01   9.99999808e-01   9.99999992e-01   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00]
 [  2.26064945e-03   7.51951682e-02   2.72690549e-01   5.58148165e-01
    8.09694336e-01   9.43357420e-01   9.95251161e-01   9.99607748e-01
    9.99986829e-01   9.99999970e-01   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00]
 [  5.05506585e-01   5.63656405e-01   9.37061187e-01   9.70295878e-01
    9.99084532e-01   9.99597129e-01   9.99997161e-01   9.99999904e-01
    9.99999909e-01   9.99999909e-01   9.99999909e-01   9.99999909e-01
    9.99999909e-01   9.99999909e-01   9.99999909e-01   9.99999909e-01
    9.99999909e-01   9.99999909e-01   9.99999909e-01   9.99999909e-01
    9.99999909e-01   9.99999909e-01   9.99999909e-01   9.99999909e-01
    9.99999909e-01   9.99999909e-01   9.99999909e-01   9.99999909e-01
    9.99999909e-01   9.99999909e-01   9.99999909e-01   9.99999909e-01
    9.99999909e-01   9.99999909e-01   9.99999910e-01   9.99999913e-01
    9.99999913e-01   9.99999913e-01   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00]
 [  6.32606620e-06   9.98719225e-01   9.98907328e-01   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00   1.00000000e+00   1.00000000e+00
    1.00000000e+00   1.00000000e+00]]
best_match[0:5] [0 1 3 0 1]
SVM classify...
Model supports probability estimates, but disabled in predicton.
Accuracy = 3.20667% (1924/60000) (classification)
Classification of training data:  [ 0.  0.  0. ...,  0.  0.  0.]
Classifier trained in time 0.563 s
Training Images Classified in time 1171.787 s
Classification/Regression over Training Set in 831.748 s
value.shape= (50000,)
labels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
acc_probs[0:5] [[ 0.38023238  0.80907003  0.98123587  0.99975574  0.99999994  1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.        ]
 [ 0.33826919  0.71701485  0.90608     0.97847497  0.99825381  0.99992613
   0.9999985   1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.        ]
 [ 0.897795    0.89795762  0.90663913  0.99985402  0.99999912  0.99999974
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.        ]
 [ 0.3673927   0.78443313  0.91092337  0.99020548  0.99997245  0.99999995
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.        ]
 [ 0.35869919  0.80668138  0.99515461  0.99999687  1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.        ]]
best_match[0:5] [1 1 0 1 1]
Model supports probability estimates, but disabled in predicton.
Accuracy = 3.18% (1590/50000) (classification)
labels_kNN_seenid.shape= (50000,)
correct_labels_seenid.shape= (50000,)
Classification/Regression over Seen Id in 690.253 s
Loading test images, new ids...
Loading  18000 Images: width=256, height=192  subimage_width=128,subimage_height=128
color_background_filter is: None
18000  Images loaded in 55.194 s
Execution over New Id testing set...
Input Signal: New Id test images
1.0
Execution over New Id in 317.585 s
value.shape= (18000,)
labels= [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
acc_probs[0:5] [[ 0.38022716  0.61655172  0.87213089  0.97621627  0.99891509  0.99993647
   0.99999935  1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.        ]
 [ 0.77653868  0.95475045  0.99856704  0.9999967   1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.        ]
 [ 0.42896647  0.72509789  0.90424924  0.97803148  0.99733294  0.99973054
   0.99998761  0.99999965  0.99999999  1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.        ]
 [ 0.01964107  0.11319168  0.90939848  0.99991052  1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.        ]
 [ 0.13694827  0.34147949  0.47889252  0.72351948  0.93882753  0.98844092
   0.99770002  0.99989566  0.99993353  0.99999812  0.99999998  1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.          1.          1.          1.          1.          1.
   1.          1.        ]]
best_match[0:5] [1 0 1 2 3]
Model supports probability estimates, but disabled in predicton.
Accuracy = 2.91111% (524/18000) (classification)
Classification/Regression over New Id in 247.263 s
Computing typical delta, eta values for Training SFA Signal
delta_train= [ 0.23128404  0.28331601  0.39174551  0.48465603  0.68701742  0.73011971
  0.93307614  0.97814871  1.18327487  1.26031874  1.35299604  1.45377441
  1.68996236  1.67233014  2.41558247  1.7580418   1.64976354  1.4812972
  2.18331256  1.56702238  1.62106495  1.77421843  2.25508422  1.92207426
  1.85282357  2.21338384  1.54937377  1.36802236  1.42476687  1.74795542
  1.36180101  1.62240481  1.87800707  2.01782036  1.8196357   1.60113748
  1.47079184  1.78234894  1.98620868  1.59292481  1.54937304  1.45744929
  1.71378106  2.19285485  2.29316329  1.91355954  2.0721945   1.51018665
  1.82032753  2.2388432   2.05073012  1.98081375  1.74195656  1.64217286
  1.75990797  1.77519267  2.4477152   2.33827556  1.79382311  1.47331209]
eta_train= [  3.84439601   4.20953877   4.91992374   5.61390534   6.64271069
   6.82445045   7.67185181   7.9300453    8.46813598   8.7703996
   9.3076375    9.59424853   9.96072701  10.0211972    6.85835296
   9.87140925   9.6778713    7.30397242   7.1790581    8.7551959
   8.78467897   8.48068986   8.15659754   8.28828983   7.79272365
   8.22265508   9.2256702    8.32564589   8.51051491   7.98933911
   8.98035902   8.6534103    8.95340543   8.84074905   8.45612386
   8.53723882   8.36711991   9.59531241   9.40434539   9.56472078
   8.76357913   9.22400741   9.46967633   9.54660943   9.54414746
   9.05307681   8.22162136   9.63424393   8.43009634   8.58245678
   9.05548863   8.10161565   9.26929287   9.5343522    9.07758006
   9.49432407   9.78174073   9.50060194   9.40554931   9.46791841]
brute_delta_train= [ 0.22723102  0.26452976  0.35581487  0.43920197  0.61537518  0.61827544
  0.78218984  0.81266577  0.97786088  1.02156876  1.15208842  1.1587268
  1.28755329  1.31842088  1.32918039  1.37389067  1.39146565  1.26982022
  1.53274833  1.404675    1.41179196  1.3987058   1.40637079  1.52080362
  1.54225472  1.50577877  1.46274568  1.52004133  1.47755321  1.48537961
  1.47352668  1.49170968  1.47464806  1.43829811  1.53507423  1.49610414
  1.48196828  1.4603658   1.39822626  1.50432921  1.55324766  1.54843225
  1.49189563  1.51056125  1.59294192  1.5207526   1.48604826  1.60749626
  1.63413611  1.62131342  1.56693392  1.55833513  1.57919551  1.57832907
  1.49923357  1.60782168  1.58936709  1.60933316  1.55043054  1.58450899]
Computing typical delta, eta values for New Id SFA Signal
typical delta_newid= [ 0.24068663  0.29746146  0.40361741  0.49590462  0.6956796   0.70659907
  0.8435113   0.93229769  1.07166876  1.17697645  1.29138717  1.30146121
  1.25278625  1.29564321  0.49037478  1.27399019  1.1211952   0.46158955
  0.63469092  0.70114332  0.74698477  0.56991385  0.59622322  0.62071534
  0.52178289  0.65802656  0.72468716  0.60674365  0.60425848  0.58800055
  0.53449678  0.62531838  0.70267123  0.61392255  0.59914488  0.61600302
  0.57457628  0.69041231  0.68513622  0.73219267  0.66861201  0.66109867
  0.74538679  0.73858021  0.84861477  0.72966785  0.68708049  0.90583404
  0.67143453  0.70020781  0.73908601  0.70509566  0.83800999  0.85777044
  0.90896354  0.9288811   0.91628495  1.04698725  0.97345812  0.95742017]
typical eta_newid= [ 3.87241484  4.29438459  5.0106471   5.56972709  6.5865992   6.64555244
  7.26478243  7.64052659  8.17446892  8.57637875  8.9715181   9.01505468
  8.84528363  8.98271051  5.50062449  8.90595848  8.35917185  5.3079558
  6.24627835  6.58846563  6.82375595  5.92191543  6.05497872  6.15202715
  5.67108385  6.36783993  6.67916518  6.12292508  6.09534446  6.02324482
  5.73088141  6.19298946  6.60024686  6.13124445  6.05794883  6.15464845
  5.95870725  6.5321883   6.48923441  6.73631174  6.41572966  6.38872977
  6.77715326  6.74407674  7.22967271  6.71549452  6.5122691   7.48394552
  6.43914383  6.55723587  6.74193591  6.59404086  7.18848697  7.26868759
  7.49273257  7.56291556  7.51196914  8.03764623  7.71623733  7.70127911]
brute_delta_newid= [ 0.23096836  0.26569614  0.36652451  0.44564317  0.61428294  0.62478463
  0.78203005  0.8110664   0.95572035  1.01178754  1.12502303  1.13250127
  1.12424811  1.19528976  0.48609458  1.14638684  1.02075015  0.4456031
  0.6427002   0.67531723  0.71802899  0.54111409  0.59059739  0.60411602
  0.52354761  0.65199615  0.69461589  0.6057905   0.58210563  0.56373726
  0.54543661  0.62818026  0.68791722  0.59641314  0.59832288  0.62062252
  0.57702347  0.68134666  0.69087727  0.75715788  0.63837783  0.69314234
  0.75155871  0.75361313  0.86267361  0.73842208  0.71008129  0.8945461
  0.66719369  0.68635955  0.76451887  0.71535577  0.83568429  0.86930165
  0.93853068  0.95593507  0.95153519  1.02976637  0.97753939  0.99646725]
computed delta/eta in 225.297 ms
virtual sequence length complete =  35970000
virtual sequence length sequence =  70560000
virtual sequence length mixed =  106530000
Estimating explained variance for Train SFA Signal
Fast inverse not available, not estimating explained variance
Not estimating explained variance with kNN
Not estimating explained variance with kNN_lin_app
Not estimating explained variance with kNN
Computations Finished!
** Displaying Benchmark data: **
      Hierarchy construction  done in 0.306 s
      Train node #0 (PInvSwitchboard)  done in 3.258 s
      Execute node #0 (PInvSwitchboard)  done in 51.340 s
      Train node #1 (Layer)  done in 38.669 s
      Execute node #1 (Layer)  done in 51.238 s
      Train node #2 (CloneLayer)  done in 4.271 s
      Execute node #2 (CloneLayer)  done in 196.539 s
      Train node #3 (Layer)  done in 6.127 s
      Execute node #3 (Layer)  done in 79.385 s
      Train node #4 (PInvSwitchboard)  done in 3.045 s
      Execute node #4 (PInvSwitchboard)  done in 35.968 s
      Train node #5 (CloneLayer)  done in 30.845 s
      Execute node #5 (CloneLayer)  done in 152.406 s
      Train node #6 (Layer)  done in 6.633 s
      Execute node #6 (Layer)  done in 70.666 s
      Train node #7 (PInvSwitchboard)  done in 2.514 s
      Execute node #7 (PInvSwitchboard)  done in 26.570 s
      Train node #8 (CloneLayer)  done in 23.512 s
      Execute node #8 (CloneLayer)  done in 105.552 s
      Train node #9 (Layer)  done in 4.497 s
      Execute node #9 (Layer)  done in 56.029 s
      Train node #10 (PInvSwitchboard)  done in 1.878 s
      Execute node #10 (PInvSwitchboard)  done in 20.902 s
      Train node #11 (CloneLayer)  done in 20.831 s
      Execute node #11 (CloneLayer)  done in 97.540 s
      Train node #12 (Layer)  done in 3.866 s
      Execute node #12 (Layer)  done in 68.088 s
      Train node #13 (PInvSwitchboard)  done in 2.089 s
      Execute node #13 (PInvSwitchboard)  done in 20.560 s
      Train node #14 (CloneLayer)  done in 18.213 s
      Execute node #14 (CloneLayer)  done in 86.685 s
      Train node #15 (Layer)  done in 4.451 s
      Execute node #15 (Layer)  done in 51.843 s
      Train node #16 (PInvSwitchboard)  done in 0.939 s
      Execute node #16 (PInvSwitchboard)  done in 6.796 s
      Train node #17 (CloneLayer)  done in 7.206 s
      Execute node #17 (CloneLayer)  done in 40.944 s
      Train node #18 (Layer)  done in 1.508 s
      Execute node #18 (Layer)  done in 19.691 s
      Train node #19 (PInvSwitchboard)  done in 0.581 s
      Execute node #19 (PInvSwitchboard)  done in 2.665 s
      Train node #20 (CloneLayer)  done in 3.051 s
      Execute node #20 (CloneLayer)  done in 20.106 s
      Train node #21 (Layer)  done in 0.861 s
      Execute node #21 (Layer)  done in 11.145 s
      Train node #22 (PInvSwitchboard)  done in 0.327 s
      Execute node #22 (PInvSwitchboard)  done in 1.407 s
      Train node #23 (CloneLayer)  done in 1.528 s
      Execute node #23 (CloneLayer)  done in 10.071 s
      Train node #24 (Layer)  done in 0.432 s
      Execute node #24 (Layer)  done in 5.423 s
      Train node #25 (PInvSwitchboard)  done in 0.141 s
      Execute node #25 (PInvSwitchboard)  done in 0.658 s
      Train node #26 (CloneLayer)  done in 0.409 s
      Execute node #26 (CloneLayer)  done in 4.920 s
      Train node #27 (Layer)  done in 0.220 s
      Execute node #27 (Layer)  done in 3.223 s
      Train node #28 (PInvSwitchboard)  done in 0.080 s
      Execute node #28 (PInvSwitchboard)  done in 0.411 s
      Train node #29 (CloneLayer)  done in 0.310 s
      Execute node #29 (CloneLayer)  done in 2.575 s
      Train node #30 (Layer)  done in 0.104 s
      Execute node #30 (Layer)  done in 1.062 s
      Train node #31 (PInvSwitchboard)  done in 0.039 s
      Execute node #31 (PInvSwitchboard)  done in 0.161 s
      Train node #32 (CloneLayer)  done in 0.150 s
      Execute node #32 (CloneLayer)  done in 1.320 s
      Train node #33 (Layer)  done in 0.058 s
      Execute node #33 (Layer)  done in 0.296 s
      Network training  (specialized way)  done in 1695.465 s
      Computation of delta, eta values for Train SFA Signal  done in 0.589 s
      Training Classifier/Regression GC  done in 0.563 s
      Classification of Training Images  done in 1171.787 s
Classification/Regression Performance: 
[ 0  0  0 ..., 49 49 49]
[ 0.  0.  0. ...,  0.  0.  0.]
(18000,) (18000,)
Comparisson of MAE for RMSE estimation and MAE estimation
regression_Gauss_newid[100:150] = [-41.91096898 -40.86896023 -43.34223424 -39.40461914 -43.45494992
 -36.3622258  -42.47176471 -39.96545834 -41.81920895 -42.49010125
 -42.60619432 -43.44494454 -42.1909692  -42.23519932 -43.00937931
 -43.1420898  -42.27975614 -36.52357458 -42.37837872 -41.33935069
 -43.47971138 -43.55592147 -36.3476188   -2.2057836  -43.02972133
 -43.85544156 -43.49265479 -43.51908948 -42.83663394 -43.55050768
 -42.08662831 -42.67532933 -42.17888795  42.59768312 -42.55856044
 -42.86975023 -42.58936154 -37.82168835 -43.36041168 -41.96825688
 -39.96939715 -42.73222224 -40.9452416  -39.83984457 -41.96962998
 -40.32251375 -40.69845995 -43.1095809  -42.02878017 -41.23318902]
regressionMAE_Gauss_newid[100:150] = [-42.30084602 -40.50081002 -44.10088202 -40.50081002 -44.10088202
 -36.90073801 -42.30084602 -40.50081002 -42.30084602 -42.30084602
 -42.30084602 -44.10088202 -42.30084602 -42.30084602 -42.30084602
 -42.30084602 -42.30084602 -36.90073801 -42.30084602 -40.50081002
 -44.10088202 -44.10088202 -35.10070201  24.30048601 -44.10088202
 -44.10088202 -44.10088202 -44.10088202 -42.30084602 -44.10088202
 -42.30084602 -42.30084602 -42.30084602  44.10088202 -42.30084602
 -42.30084602 -42.30084602 -38.70077402 -44.10088202 -42.30084602
 -40.50081002 -44.10088202 -40.50081002 -38.70077402 -42.30084602
 -40.50081002 -40.50081002 -44.10088202 -42.30084602 -40.50081002]
diff MAE-RMSE=  [ -3.89877033e-01   3.68150213e-01  -7.58647773e-01  -1.09619087e+00
  -6.45932101e-01  -5.38512219e-01   1.70918691e-01  -5.35351673e-01
  -4.81637066e-01   1.89255237e-01   3.05348303e-01  -6.55937477e-01
  -1.09876822e-01  -6.56466948e-02   7.08533292e-01   8.41243784e-01
  -2.10898782e-02  -3.77163432e-01   7.75327034e-02   8.38540678e-01
  -6.21170634e-01  -5.44960550e-01   1.24691678e+00   2.65062696e+01
  -1.07116068e+00  -2.45440457e-01  -6.08227224e-01  -5.81792538e-01
   5.35787921e-01  -5.50374338e-01  -2.14217704e-01   3.74483313e-01
  -1.21958070e-01   1.50319890e+00   2.57714426e-01   5.68904214e-01
   2.88515518e-01  -8.79085670e-01  -7.40470334e-01  -3.32589132e-01
  -5.31412870e-01  -1.36865978e+00   4.44431586e-01   1.13907055e+00
  -3.31216035e-01  -1.78296266e-01   1.97649931e-01  -9.91301121e-01
  -2.72065850e-01   7.32379007e-01]
worst[-50:] diff MAE-RMSE=  [   12 17151  5169  9758  9212  7980 11101 16895 17537  1574 17516 14914
  1007  3777  5773   752 17976  3972   574  4260  2634  4445  1658  5798
  2250 16816   663  2216    53  4818 17471 12204 15009   803   205  1282
  2684   176 16000   283   123 15756 17010 17928 15717 14185  4491  3448
  9344 17543]
regression_Gauss_newid[worst[-50:]]= [ 12.74954055  26.61657514  -6.73501771   4.93366558 -11.30031153
  -6.60343623 -22.45357119 -27.74400369  27.16604561  14.66111026
  13.48059557  10.61058981  19.26408654 -19.24091533   2.4576129
 -13.51608645 -12.08929448  -7.59612703 -21.76996677  -3.00650898
 -18.92719387  -0.87981466 -11.63153889  -9.78125138  -6.10709612
  20.47346032  11.33641163  -5.77195261 -23.62219776  19.53521569
  22.60618604  -0.82296831  -4.24661704   3.29810851  17.39347688
  -0.69813325  16.03680613 -15.65898858  -4.13602035  -1.83751767
  -2.2057836  -11.61530368 -12.90426676  14.25375265  -2.12264901
  -5.78998783   9.22367364   5.28503546  -4.78615029  -3.66498414]
regressionMAE_Gauss_newid[worst[-50:]]= [ 26.10052201  40.50081002 -20.70041401  18.90037801   2.700054
 -20.70041401 -36.90073801 -42.30084602  42.30084602  -0.900018
  29.70059401  27.90055801  36.90073801 -36.90073801 -15.30030601
 -31.50063001   6.300126   -26.10052201 -40.50081002 -22.50045001
 -38.70077402 -20.70041401 -31.50063001 -29.70059401 -26.10052201
  40.50081002  31.50063001 -26.10052201 -44.10088202  40.50081002
  44.10088202 -22.50045001 -26.10052201  26.10052201  40.50081002
  22.50045001  40.50081002 -40.50081002 -29.70059401  24.30048601
  24.30048601 -38.70077402 -40.50081002  42.30084602  26.10052201
  24.30048601  40.50081002  36.90073801 -38.70077402 -38.70077402]
correct_labels_newid[worst[-50:]]= [-44.93999667  40.75976443 -19.15356409   3.79271071   1.06255903
  -5.09778321  10.50808378  39.47969332  42.68987166 -37.12956275
  42.58486583  29.57414301 -39.96472026 -26.11395078 -16.1333963
 -41.2397911   44.88499361 -25.13889661 -42.12984055 -23.6988166
 -31.82926829 -22.77376521 -36.70953942 -16.00838935 -33.74937497
  39.08467137 -41.68481582 -33.91938441 -44.73498528 -20.90866159
  42.35985333  16.02339019  30.0491694  -40.98477693 -43.97494305
 -38.58964387 -31.5792544  -44.11995111  35.00444469 -43.58492138
 -44.38496583  33.78437691  40.05472526  44.64498028  33.58936608
  25.9289405  -22.54375243 -27.75904217   1.7225957   42.71987333]
N1= 2.23021262427
N2= 2.13614228677
Train: 0.020 CR_NCC, 0.020 CR_kNN, CR_Gauss 0.400, CR_SVM 0.434, MSE_NCC 675.023, MSE_kNN 675.023, MSE_Gauss 18.849, MSE3_SVM 24.917, MSE2_SVM 24.917, MSE_SVM 24.917, MSE_LR 675.023, MAE 1.798, MAE(Opt) 1.920
Seen Id: 0.020 CR_NCC, 0.020 CR_kNN, CR_Gauss 0.406, CR_SVM 0.413, MSE_NCC 675.027, MSE_kNN 675.027, MSE_Gauss 29.454, MSE3_SVM 32.377, MSE2_SVM 32.377, MSE_SVM 32.377, MSE_LR 675.027, MAE 2.108, MAE(Opt) 2.193
New Id: 0.020 CR_NCC, 0.020 CR_kNN, CR_Gauss 0.365, CR_SVM 0.395, MSE_NCC 675.075, MSE_kNN 675.075, MSE_Gauss 28.153, MSE3_SVM 30.063, MSE2_SVM 30.063, MSE_SVM 30.063, MSE_LR 675.075 , MAE 2.136, MAE(Opt) 2.230
Train:   RMSE_NCC 25.981, RMSE_kNN 25.981, RMSE_Gauss 4.342, RMSE3_SVM 4.992, RMSE2_SVM 4.992, RMSE_SVM 4.992, RMSE_LR 25.981
Seen Id: RMSE_NCC 25.981, RMSE_kNN 25.981, RMSE_Gauss 5.427, RMSE3_SVM 5.690, RMSE2_SVM 5.690, RMSE_SVM 5.690, RMSE_LR 25.981
New Id:  RMSE_NCC 25.982, RMSE_kNN 25.982, RMSE_Gauss 5.306, RMSE3_SVM 5.483, RMSE2_SVM 5.483, RMSE_SVM 5.483, RMSE_LR 25.982
Computing average SFA...
50 60 (60000, 60) 1200 1200
50 Blocks used for averages
Program successfully finished
